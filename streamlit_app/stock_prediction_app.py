# -*- coding: utf-8 -*-
"""
ì£¼ê°€ ì˜ˆì¸¡ í™•ë¥  í™•ì¸ ìŠ¤íŠ¸ë¦¼ë¦¿ ì•±
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from datetime import datetime, timedelta
import FinanceDataReader as fdr
import sys
import os
import importlib
import io
import json
import zipfile
import pickle
import base64
import html as html_lib
import urllib.request as urllib_request

# ì¼ë¶€ í™˜ê²½ì—ì„œ ì˜ëª»ëœ í”„ë¡ì‹œ(ì˜ˆ: 127.0.0.1:9)ê°€ ì„¤ì •ë˜ì–´
# Yahoo/FinanceDataReader/requests í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´, í•´ë‹¹ ì¼€ì´ìŠ¤ë§Œ ìë™ í•´ì œí•©ë‹ˆë‹¤.
def _disable_bad_local_proxy_env():
    bad_markers = ("127.0.0.1:9", "localhost:9")
    keys = (
        "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY",
        "http_proxy", "https_proxy", "all_proxy",
    )
    removed = False
    for k in keys:
        v = os.environ.get(k)
        if v and any(m in str(v) for m in bad_markers):
            os.environ.pop(k, None)
            removed = True
    if removed:
        # requests/urllib ê³„ì—´ì´ í”„ë¡ì‹œë¥¼ ìš°íšŒí•˜ë„ë¡ ì„¤ì •
        os.environ["NO_PROXY"] = "*"
        os.environ["no_proxy"] = "*"

_disable_bad_local_proxy_env()

def _force_requests_no_proxy_if_bad_local_proxy():
    """
    requestsëŠ” í™˜ê²½ë³€ìˆ˜ë¿ ì•„ë‹ˆë¼ Windows ì‹œìŠ¤í…œ í”„ë¡ì‹œë„ ì½ì„ ìˆ˜ ìˆì–´,
    envë¥¼ ì§€ì›Œë„ 127.0.0.1:9 ê°™ì€ 'ì£½ì€ í”„ë¡ì‹œ'ë¥¼ ê³„ì† íƒˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì´ ê²½ìš°ì—ë§Œ requests í˜¸ì¶œì„ ì„¸ì…˜(trust_env=False, proxies={})ë¡œ ê°•ì œí•©ë‹ˆë‹¤.
    """
    bad_markers = ("127.0.0.1:9", "localhost:9")

    def _has_bad_proxy() -> bool:
        # env
        for k in ("HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy"):
            v = os.environ.get(k)
            if v and any(m in str(v) for m in bad_markers):
                return True
        # system proxy (urllib)
        try:
            px = urllib_request.getproxies() or {}
            for v in px.values():
                if v and any(m in str(v) for m in bad_markers):
                    return True
        except Exception:
            pass
        return False

    if not _has_bad_proxy():
        return

    try:
        import requests
    except Exception:
        return

    _orig_request = requests.request

    def _request_no_proxy(method, url, **kwargs):
        # ì™¸ë¶€ì—ì„œ proxiesë¥¼ ëª…ì‹œí•œ ê²½ìš°ëŠ” ì¡´ì¤‘
        if "proxies" not in kwargs:
            kwargs["proxies"] = {}
        timeout = kwargs.get("timeout", None)
        if timeout is None:
            kwargs["timeout"] = 20
        with requests.Session() as s:
            s.trust_env = False
            return s.request(method=method, url=url, **kwargs)

    # requests.get/post/... ëŠ” requests.requestë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ê²ƒë§Œ ê°ˆì•„ë¼ìš°ë©´ ëŒ€ë¶€ë¶„ ì»¤ë²„ë©ë‹ˆë‹¤.
    requests.request = _request_no_proxy
    requests.api.request = _request_no_proxy
    # ë³´ìˆ˜ì ìœ¼ë¡œ getë„ ì§ì ‘ ë°”ê¿”ë‘ (FinanceDataReaderê°€ requests.get ì§ì ‘ í˜¸ì¶œ)
    requests.get = lambda url, **kwargs: _request_no_proxy("GET", url, **kwargs)
    requests.post = lambda url, **kwargs: _request_no_proxy("POST", url, **kwargs)

_force_requests_no_proxy_if_bad_local_proxy()

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    import stock_analysis_refactored as sar
    sar = importlib.reload(sar)  # ìŠ¤íŠ¸ë¦¼ë¦¿ ì¬ì‹¤í–‰ ì‹œ ìµœì‹  ì½”ë“œ ë°˜ì˜

    StockDataCollector = sar.StockDataCollector
    StockPredictor = sar.StockPredictor
    get_sp500_tickers = sar.get_sp500_tickers
    get_bond_data = sar.get_bond_data
    get_vix_data = sar.get_vix_data
    calculate_rsi = sar.calculate_rsi
    calculate_macd = sar.calculate_macd
    calculate_moving_averages = sar.calculate_moving_averages
    prepare_prediction_data = sar.prepare_prediction_data
    build_feature_matrix = sar.build_feature_matrix
except ImportError as e:
    import streamlit as st
    st.error(f"ëª¨ë“ˆ import ì˜¤ë¥˜: {str(e)}\n\nstock_analysis_refactored.py íŒŒì¼ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì£¼ê°€ ì˜ˆì¸¡ í™•ë¥  ë¶„ì„",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================
# Shinhan Theme (UI/Charts)
# =========================

SHINHAN_BLUE = "#0046ff"
SHINHAN_NAVY = "#00236e"
SHINHAN_SKY = "#4baff5"
SHINHAN_LIGHT = "#8cd2f5"
TEXT_DARK = "#0b1220"
BG_SOFT = "#f5f8ff"

def build_screen_analysis_report_html_from_session_state() -> str | None:
    """
    í™”ë©´(ë¶„ì„ ê²°ê³¼) HTML ë¦¬í¬íŠ¸ ìƒì„±.

    - Plotly figureëŠ” ê°€ëŠ¥í•œ ê²½ìš° PNGë¡œ ë³€í™˜í•´ <img>ë¡œ ì €ì¥(=ì§„ì§œ 'ì´ë¯¸ì§€' í˜•íƒœ)
    - PNG ë³€í™˜ì´ ë¶ˆê°€í•˜ë©´(ì˜ˆ: kaleido ë¯¸ì„¤ì¹˜) Plotly interactive HTMLë¡œ fallback
    """
    generated_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    up_prob = st.session_state.get("report_current_up_prob")
    down_prob = st.session_state.get("report_current_down_prob")
    up_recent5 = st.session_state.get("report_recent5_up")
    down_recent5 = st.session_state.get("report_recent5_down")

    sma_asof = st.session_state.get("sma50_asof")
    sma_above_df = st.session_state.get("sma50_above_df")
    sma_below_df = st.session_state.get("sma50_below_df")
    sma_view = st.session_state.get("report_sma50_view")  # ìµœì‹  ì‚¬ìš©ìê°€ ì§€ì •í•œ ì •ë ¬/í‘œì‹œ ì„¤ì •

    ret_stats = st.session_state.get("report_return_stats")
    ret_stats_fig_json = st.session_state.get("report_return_stats_fig_json")
    sma_diffpct = st.session_state.get("report_sma50_diffpct")
    sma_diffpct_fig_json = st.session_state.get("report_sma50_diffpct_fig_json")

    has_sma_tables = (
        isinstance(sma_above_df, pd.DataFrame)
        and isinstance(sma_below_df, pd.DataFrame)
        and (not sma_above_df.empty or not sma_below_df.empty)
    )
    has_recent5 = bool(up_recent5) or bool(down_recent5)
    has_return_stats = bool(ret_stats) and isinstance(ret_stats, dict) and bool(ret_stats.get("rows"))
    has_sma_diffpct = bool(sma_diffpct) and isinstance(sma_diffpct, dict) and bool(sma_diffpct.get("rows"))

    fig_items: list[tuple[str, str]] = []
    # (title, session_key_of_json)
    for title, key in [
        ("ìƒìŠ¹ í™•ë¥  ì¶”ì´", "report_fig_prob_trend_json"),
        ("ìµœê·¼ 5ë…„ ì§€ìˆ˜ ë¹„êµ vs ìƒìŠ¹ í™•ë¥ ", "report_fig_index_compare_json"),
        ("í•˜ë½ í™•ë¥  ì¶”ì´", "report_fig_down_trend_json"),
        ("ìµœê·¼ 5ë…„ ì§€ìˆ˜ ë¹„êµ vs í•˜ë½ í™•ë¥ ", "report_fig_down_index_compare_json"),
    ]:
        if st.session_state.get(key):
            fig_items.append((title, key))

    if up_prob is None and down_prob is None and not fig_items and not has_sma_tables and not has_recent5 and not has_return_stats and not has_sma_diffpct:
        return None

    def _fmt_pct(p):
        try:
            return f"{float(p) * 100:.2f}%"
        except Exception:
            return "-"

    def _df_to_html_table(df: pd.DataFrame) -> str:
        try:
            tmp = df.copy()

            # ë³´ê¸° ì¢‹ì€ í¬ë§·(ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ)
            if "MarketCap" in tmp.columns:
                def _fmt_mcap(x):
                    try:
                        return f"{float(x):,.0f}"
                    except Exception:
                        return ""
                tmp["MarketCap"] = tmp["MarketCap"].apply(lambda x: _fmt_mcap(x) if pd.notna(x) else "")

            for col in ["Adj Close", "SMA50"]:
                if col in tmp.columns:
                    tmp[col] = pd.to_numeric(tmp[col], errors="coerce").round(2)

            if "diff_pct" in tmp.columns:
                tmp["diff_pct"] = pd.to_numeric(tmp["diff_pct"], errors="coerce").round(2)

            return tmp.to_html(index=False, escape=True, classes="tbl")
        except Exception:
            return ""

    def _df_to_html_table_highlight_row(df: pd.DataFrame, highlight_col: str, highlight_value: str | None) -> str:
        """
        ê°„ë‹¨í•œ HTML í…Œì´ë¸” ìƒì„± + íŠ¹ì • í–‰ í•˜ì´ë¼ì´íŠ¸.
        (pandas Stylerë¥¼ HTMLë¡œ ë„£ëŠ” ê±´ í™˜ê²½/ë²„ì „ ì˜ì¡´ì´ ì»¤ì„œ ì§ì ‘ ë Œë”ë§)
        """
        if df is None or not isinstance(df, pd.DataFrame) or df.empty:
            return ""
        cols = list(df.columns)
        hv = str(highlight_value) if highlight_value is not None else None

        def esc(x):
            return html_lib.escape("" if x is None else str(x))

        out = []
        out.append("<table class='tbl' style='width:100%;'>")
        out.append("<thead><tr>" + "".join([f"<th>{esc(c)}</th>" for c in cols]) + "</tr></thead>")
        out.append("<tbody>")
        for _, row in df.iterrows():
            is_hl = False
            try:
                if hv is not None and highlight_col in df.columns:
                    is_hl = (str(row.get(highlight_col)) == hv)
            except Exception:
                is_hl = False
            style = " style='background:#fff3bf;'" if is_hl else ""
            out.append("<tr" + style + ">" + "".join([f"<td>{esc(row.get(c))}</td>" for c in cols]) + "</tr>")
        out.append("</tbody></table>")
        return "".join(out)

    def _apply_sma_view(df: pd.DataFrame) -> pd.DataFrame:
        """
        HTML ì €ì¥ ì‹œì—ë„ ì‚¬ìš©ìê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ íƒí•œ ì •ë ¬/í‘œì‹œê°œìˆ˜ ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤.
        """
        if df is None or not isinstance(df, pd.DataFrame) or df.empty:
            return df
        if not isinstance(sma_view, dict):
            return df

        sort_by = sma_view.get("sort_by")
        sort_dir = sma_view.get("sort_dir")  # "ë‚´ë¦¼ì°¨ìˆœ"/"ì˜¤ë¦„ì°¨ìˆœ"
        top_n = sma_view.get("top_n")

        tmp = df.copy()
        try:
            if sort_by and sort_by in tmp.columns:
                if sort_by in {"diff_pct", "MarketCap", "Adj Close", "SMA50"}:
                    tmp[sort_by] = pd.to_numeric(tmp[sort_by], errors="coerce")
                ascending = (sort_dir == "ì˜¤ë¦„ì°¨ìˆœ")
                tmp = tmp.sort_values(sort_by, ascending=ascending, na_position="last")
        except Exception:
            pass

        try:
            n = int(top_n) if top_n is not None else None
            if n is not None and n > 0:
                n = min(n, len(tmp))
                tmp = tmp.head(n)
        except Exception:
            pass

        return tmp.reset_index(drop=True)

    def _try_plotly_png_base64(fig) -> str | None:
        try:
            img_bytes = pio.to_image(fig, format="png", scale=2)
            return base64.b64encode(img_bytes).decode("ascii")
        except Exception:
            return None

    plotlyjs_included = False
    body_parts: list[str] = []

    # ìš”ì•½ ì˜ì—­(í…ìŠ¤íŠ¸)
    body_parts.append(f"<h2 style='margin:0 0 8px 0;'>í™”ë©´ ë¶„ì„ ê²°ê³¼</h2>")
    body_parts.append(f"<div style='color:#555;margin:0 0 16px 0;'>ìƒì„± ì‹œê°: {generated_at}</div>")

    # í™•ë¥  ìš”ì•½(ìˆìœ¼ë©´)
    if up_prob is not None or down_prob is not None:
        body_parts.append("<div style='display:flex;gap:12px;flex-wrap:wrap;margin:0 0 18px 0;'>")
        if up_prob is not None:
            body_parts.append(
                f"<div style='border:1px solid #e6e8ef;border-radius:12px;padding:12px 14px;min-width:220px;'>"
                f"<div style='font-size:13px;color:#555;'>í˜„ì¬ ìƒìŠ¹ í™•ë¥ </div>"
                f"<div style='font-size:22px;font-weight:800;color:#0b1220;margin-top:6px;'>{_fmt_pct(up_prob)}</div>"
                f"</div>"
            )
        if down_prob is not None:
            body_parts.append(
                f"<div style='border:1px solid #e6e8ef;border-radius:12px;padding:12px 14px;min-width:220px;'>"
                f"<div style='font-size:13px;color:#555;'>í˜„ì¬ í•˜ë½ í™•ë¥ </div>"
                f"<div style='font-size:22px;font-weight:800;color:#0b1220;margin-top:6px;'>{_fmt_pct(down_prob)}</div>"
                f"</div>"
            )
        body_parts.append("</div>")

    # ìµœê·¼ 5ì¼ ìƒìŠ¹/í•˜ë½ í™•ë¥  ìš”ì•½
    if has_recent5:
        body_parts.append("<h3 style='margin:18px 0 10px 0;'>ğŸ“… ìµœê·¼ 5ì¼ í™•ë¥  ìš”ì•½</h3>")

        rows_by_date: dict[str, dict] = {}
        for rows, k in [(up_recent5, "up"), (down_recent5, "down")]:
            if not rows:
                continue
            if isinstance(rows, list):
                for r in rows:
                    try:
                        d = str(r.get("date", ""))
                        p = r.get("prob", None)
                        if not d:
                            continue
                        rows_by_date.setdefault(d, {})
                        rows_by_date[d][k] = p
                    except Exception:
                        continue

        dates = sorted(rows_by_date.keys())
        body_parts.append(
            "<div style='border:1px solid #e6e8ef;border-radius:14px;overflow:hidden;background:#fff;'>"
            "<table class='tbl' style='width:100%;'>"
            "<thead><tr><th>ë‚ ì§œ</th><th>ìƒìŠ¹ í™•ë¥ </th><th>í•˜ë½ í™•ë¥ </th></tr></thead><tbody>"
        )
        for d in dates:
            up_v = rows_by_date[d].get("up", None)
            dn_v = rows_by_date[d].get("down", None)
            body_parts.append(
                "<tr>"
                f"<td>{html_lib.escape(d)}</td>"
                f"<td>{_fmt_pct(up_v) if up_v is not None else '-'}</td>"
                f"<td>{_fmt_pct(dn_v) if dn_v is not None else '-'}</td>"
                "</tr>"
            )
        body_parts.append("</tbody></table></div>")

    # SMA50 ìœ„/ì•„ë˜ ê¸°ì—… ëª©ë¡
    if has_sma_tables:
        body_parts.append("<h3 style='margin:18px 0 10px 0;'>ğŸ“Œ SMA50 ìœ„/ì•„ë˜ ê¸°ì—… ëª©ë¡</h3>")
        if sma_asof is not None:
            try:
                asof_str = sma_asof.strftime("%Y-%m-%d") if hasattr(sma_asof, "strftime") else str(sma_asof)[:10]
            except Exception:
                asof_str = str(sma_asof)[:10]
            body_parts.append(f"<div style='color:#555;margin:0 0 10px 0;'>ê¸°ì¤€ì¼: {html_lib.escape(asof_str)}</div>")

        # ì‚¬ìš©ì ìµœì‹  ì •ë ¬/í‘œì‹œê°œìˆ˜ ì„¤ì • ë°˜ì˜
        above_view = _apply_sma_view(sma_above_df if isinstance(sma_above_df, pd.DataFrame) else pd.DataFrame())
        below_view = _apply_sma_view(sma_below_df if isinstance(sma_below_df, pd.DataFrame) else pd.DataFrame())
        above_html = _df_to_html_table(above_view if isinstance(above_view, pd.DataFrame) else pd.DataFrame())
        below_html = _df_to_html_table(below_view if isinstance(below_view, pd.DataFrame) else pd.DataFrame())
        body_parts.append("<div class='grid2'>")
        body_parts.append(
            "<div style='border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
            "<div style='font-weight:800;margin:4px 0 10px 0;'>âœ… SMA50 ìœ„(ê°€ê²© &gt; SMA50)</div>"
            f"{above_html if above_html else '<div style=\"color:#777;\">ë°ì´í„° ì—†ìŒ</div>'}"
            "</div>"
        )
        body_parts.append(
            "<div style='border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
            "<div style='font-weight:800;margin:4px 0 10px 0;'>âŒ SMA50 ì•„ë˜(ê°€ê²© &lt; SMA50)</div>"
            f"{below_html if below_html else '<div style=\"color:#777;\">ë°ì´í„° ì—†ìŒ</div>'}"
            "</div>"
        )
        body_parts.append("</div>")

    # ì˜ˆì¸¡í™•ë¥ ë³„ í–¥í›„ ìˆ˜ìµë¥  í†µê³„(í‘œ + ê·¸ë˜í”„)
    if has_return_stats:
        try:
            kind = html_lib.escape(str(ret_stats.get("kind", "")))
            lookback = html_lib.escape(str(ret_stats.get("lookback_days", "")))
            bin_size = html_lib.escape(str(ret_stats.get("bin_size", "")))
            latest_bin = ret_stats.get("latest_bin")
            body_parts.append("<h3 style='margin:18px 0 10px 0;'>ğŸ“Š ì˜ˆì¸¡í™•ë¥ ë³„ í–¥í›„ ìˆ˜ìµë¥  í†µê³„</h3>")
            body_parts.append(f"<div style='color:#555;margin:0 0 10px 0;'>í™•ë¥  ì¢…ë¥˜: <b>{kind}</b> Â· ê¸°ê°„: ìµœê·¼ {lookback}ì¼ Â· êµ¬ê°„ í­: {bin_size}</div>")

            df_rs = pd.DataFrame(ret_stats.get("rows", []))
            # ìµœê·¼ ì˜ˆì¸¡ êµ¬ê°„ í•˜ì´ë¼ì´íŠ¸
            if "prob_bin" in df_rs.columns:
                df_rs["prob_bin"] = df_rs["prob_bin"].astype(str)
            rs_html = _df_to_html_table_highlight_row(df_rs, highlight_col="prob_bin", highlight_value=str(latest_bin) if latest_bin is not None else None)
            body_parts.append(
                "<div style='border:1px solid #e6e8ef;border-radius:14px;overflow:hidden;background:#fff;'>"
                f"{rs_html if rs_html else '<div style=\"padding:10px;color:#777;\">ë°ì´í„° ì—†ìŒ</div>'}"
                "</div>"
            )

            if ret_stats_fig_json:
                try:
                    fig = pio.from_json(ret_stats_fig_json)
                    b64 = _try_plotly_png_base64(fig)
                    if b64:
                        body_parts.append(
                            "<div style='margin-top:12px;border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                            f"<img alt='ìˆ˜ìµë¥  í†µê³„ ê·¸ë˜í”„' style='width:100%;height:auto;display:block;' src='data:image/png;base64,{b64}'/>"
                            "</div>"
                        )
                    else:
                        include_js = "cdn" if not plotlyjs_included else False
                        plotlyjs_included = True
                        div = pio.to_html(fig, full_html=False, include_plotlyjs=include_js)
                        body_parts.append(
                            "<div style='margin-top:12px;border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                            f"{div}"
                            "</div>"
                        )
                except Exception:
                    pass
        except Exception:
            pass

    # SMA50 diff_pct ì¶”ì´(Top ìƒìŠ¹) (í‘œ + ê·¸ë˜í”„)
    if has_sma_diffpct:
        try:
            period_label = html_lib.escape(str(sma_diffpct.get("period_label", "")))
            body_parts.append("<h3 style='margin:18px 0 10px 0;'>ğŸ“ˆ SMA50 diff_pct ì¶”ì´ (Top ìƒìŠ¹)</h3>")
            body_parts.append(f"<div style='color:#555;margin:0 0 10px 0;'>ê¸°ê°„: <b>{period_label}</b> Â· Top 10</div>")

            df_dp = pd.DataFrame(sma_diffpct.get("rows", []))
            dp_html = _df_to_html_table(df_dp)
            body_parts.append(
                "<div style='border:1px solid #e6e8ef;border-radius:14px;overflow:hidden;background:#fff;'>"
                f"{dp_html if dp_html else '<div style=\"padding:10px;color:#777;\">ë°ì´í„° ì—†ìŒ</div>'}"
                "</div>"
            )

            if sma_diffpct_fig_json:
                try:
                    fig = pio.from_json(sma_diffpct_fig_json)
                    b64 = _try_plotly_png_base64(fig)
                    if b64:
                        body_parts.append(
                            "<div style='margin-top:12px;border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                            f"<img alt='SMA50 diff_pct ì¶”ì´' style='width:100%;height:auto;display:block;' src='data:image/png;base64,{b64}'/>"
                            "</div>"
                        )
                    else:
                        include_js = "cdn" if not plotlyjs_included else False
                        plotlyjs_included = True
                        div = pio.to_html(fig, full_html=False, include_plotlyjs=include_js)
                        body_parts.append(
                            "<div style='margin-top:12px;border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                            f"{div}"
                            "</div>"
                        )
                except Exception:
                    pass
        except Exception:
            pass

    # Figure ì˜ì—­
    for title, key in fig_items:
        fig_json = st.session_state.get(key)
        if not fig_json:
            continue

        try:
            fig = pio.from_json(fig_json)
        except Exception:
            continue

        body_parts.append(f"<h3 style='margin:18px 0 10px 0;'>{title}</h3>")

        b64 = _try_plotly_png_base64(fig)
        if b64:
            body_parts.append(
                "<div style='border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                f"<img alt='{title}' style='width:100%;height:auto;display:block;' src='data:image/png;base64,{b64}'/>"
                "</div>"
            )
        else:
            # kaleido ë¯¸ì„¤ì¹˜ ë“±ìœ¼ë¡œ PNG ë³€í™˜ì´ ì•ˆ ë˜ë©´ interactive HTMLë¡œ ì €ì¥
            include_js = "cdn" if not plotlyjs_included else False
            plotlyjs_included = True
            div = pio.to_html(fig, full_html=False, include_plotlyjs=include_js)
            body_parts.append(
                "<div style='border:1px solid #e6e8ef;border-radius:14px;padding:10px;background:#fff;'>"
                f"{div}"
                "</div>"
            )

    html = f"""
<!doctype html>
<html lang="ko">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>í™”ë©´ ë¶„ì„ ê²°ê³¼</title>
    <style>
      body {{ font-family: Pretendard, "Noto Sans KR", "Segoe UI", system-ui, -apple-system, sans-serif; background:#f7f9ff; color:#0b1220; }}
      .wrap {{ max-width: 1100px; margin: 24px auto; padding: 0 14px; }}
      .card {{ background:#fff; border:1px solid #e6e8ef; border-radius:16px; padding:18px; box-shadow: 0 10px 30px rgba(0,35,110,0.06); }}
      h2,h3 {{ letter-spacing: -0.02em; }}
      .grid2 {{ display:grid; grid-template-columns: 1fr 1fr; gap: 12px; }}
      @media (max-width: 900px) {{ .grid2 {{ grid-template-columns: 1fr; }} }}
      table.tbl {{ border-collapse: collapse; width: 100%; font-size: 12px; }}
      table.tbl th, table.tbl td {{ border: 1px solid #e6e8ef; padding: 6px 8px; text-align: left; vertical-align: top; }}
      table.tbl th {{ background: #f3f6ff; font-weight: 800; }}
      table.tbl tr:nth-child(even) td {{ background: #fbfcff; }}
    </style>
  </head>
  <body>
    <div class="wrap">
      <div class="card">
        {''.join(body_parts)}
      </div>
    </div>
  </body>
</html>
""".strip()

    return html

def inject_shinhan_css():
    st.markdown(
        f"""
        <style>
          :root {{
            --shinhan-blue: {SHINHAN_BLUE};
            --shinhan-navy: {SHINHAN_NAVY};
            --shinhan-sky: {SHINHAN_SKY};
            --shinhan-light: {SHINHAN_LIGHT};
            --bg-soft: {BG_SOFT};
            --text-dark: {TEXT_DARK};
          }}

          /* App background */
          .stApp {{
            background: radial-gradient(1200px 600px at 10% -10%, rgba(0,70,255,0.18), transparent 60%),
                        radial-gradient(900px 500px at 95% 0%, rgba(75,175,245,0.18), transparent 55%),
                        linear-gradient(180deg, var(--bg-soft), #ffffff 70%);
          }}

          /* Main block spacing */
          [data-testid="stVerticalBlock"] > [data-testid="stVerticalBlock"] {{
            gap: 0.75rem;
          }}

          /* Typography */
          html, body, [class*="css"] {{
            font-family: "Pretendard", "Noto Sans KR", "Segoe UI", system-ui, -apple-system, sans-serif;
            color: var(--text-dark);
          }}
          h1, h2, h3 {{
            letter-spacing: -0.02em;
          }}

          /* Hero header */
          .shinhan-hero {{
            padding: 18px 18px;
            border-radius: 18px;
            background: linear-gradient(135deg, rgba(0,70,255,0.95), rgba(40,120,245,0.92));
            box-shadow: 0 14px 35px rgba(0, 35, 110, 0.18);
            color: white;
            border: 1px solid rgba(255,255,255,0.12);
          }}
          .shinhan-hero .kicker {{
            font-size: 13px;
            opacity: 0.92;
            margin: 0 0 6px 0;
          }}
          .shinhan-hero .title {{
            font-size: 28px;
            font-weight: 800;
            margin: 0;
          }}
          .shinhan-hero .subtitle {{
            margin: 8px 0 0 0;
            font-size: 14px;
            opacity: 0.92;
          }}

          /* Sidebar */
          [data-testid="stSidebar"] > div {{
            background: rgba(255,255,255,0.72);
            backdrop-filter: blur(10px);
            border-right: 1px solid rgba(0,35,110,0.10);
          }}
          [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {{
            color: var(--shinhan-navy);
          }}

          /* Buttons */
          .stButton > button {{
            border-radius: 12px !important;
            border: 1px solid rgba(0,70,255,0.28) !important;
            background: linear-gradient(135deg, var(--shinhan-blue), #2878f5) !important;
            color: #fff !important;
            box-shadow: 0 10px 22px rgba(0,70,255,0.18) !important;
            transition: transform .08s ease, box-shadow .08s ease, filter .12s ease;
          }}
          .stButton > button:hover {{
            filter: brightness(1.03);
            box-shadow: 0 14px 28px rgba(0,70,255,0.24) !important;
            transform: translateY(-1px);
          }}
          .stButton > button:active {{
            transform: translateY(0px);
            box-shadow: 0 10px 20px rgba(0,70,255,0.18) !important;
          }}

          /* Metrics as cards */
          [data-testid="stMetric"] {{
            background: rgba(255,255,255,0.78);
            border: 1px solid rgba(0,35,110,0.10);
            border-radius: 14px;
            padding: 12px 14px;
            box-shadow: 0 10px 24px rgba(0, 35, 110, 0.06);
          }}

          /* Expanders */
          details {{
            border-radius: 14px;
            border: 1px solid rgba(0,35,110,0.10);
            background: rgba(255,255,255,0.75);
            box-shadow: 0 10px 24px rgba(0, 35, 110, 0.06);
          }}
          details > summary {{
            padding: 10px 12px;
            font-weight: 650;
            color: var(--shinhan-navy);
          }}

          /* Dataframes */
          [data-testid="stDataFrame"] {{
            border-radius: 14px;
            overflow: hidden;
            border: 1px solid rgba(0,35,110,0.10);
            box-shadow: 0 10px 24px rgba(0, 35, 110, 0.06);
          }}
        </style>
        """,
        unsafe_allow_html=True,
    )

def apply_plotly_shinhan_theme():
    pio.templates.default = "plotly_white"
    pio.templates["shinhan"] = go.layout.Template(
        layout=dict(
            font=dict(family="Pretendard, Noto Sans KR, Segoe UI, sans-serif", color=TEXT_DARK),
            colorway=[SHINHAN_BLUE, SHINHAN_SKY, "#2ECC71", "#F1C40F", "#FF4B4B", SHINHAN_NAVY],
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(255,255,255,0.92)",
            xaxis=dict(gridcolor="rgba(0,35,110,0.08)", zerolinecolor="rgba(0,35,110,0.12)"),
            yaxis=dict(gridcolor="rgba(0,35,110,0.08)", zerolinecolor="rgba(0,35,110,0.12)"),
            legend=dict(bgcolor="rgba(255,255,255,0.65)", bordercolor="rgba(0,35,110,0.10)", borderwidth=1),
        )
    )
    pio.templates.default = "shinhan"

inject_shinhan_css()
apply_plotly_shinhan_theme()

# Hero title
st.markdown(
    """
    <div class="shinhan-hero">
      <div class="kicker">Shinhan-style Dashboard</div>
      <div class="title">ì£¼ê°€ ì˜ˆì¸¡ í™•ë¥  ë¶„ì„</div>
      <div class="subtitle">RandomForest ê¸°ë°˜ ìƒìŠ¹ í™•ë¥  Â· ìµœê·¼ 5ë…„ ì§€ìˆ˜ ë¹„êµ Â· SMA50 ìœ„/ì•„ë˜ ìŠ¤ìºë„ˆ</div>
    </div>
    """,
    unsafe_allow_html=True,
)

# =========================
# ìœ í‹¸: ì§€ìˆ˜ ë°ì´í„°(ìµœê·¼ 5ë…„) ì¡°íšŒ
# =========================

@st.cache_data(ttl=60 * 60 * 12, show_spinner=False)
def fetch_index_adj_close(symbol_candidates, start_date, end_date):
    """
    FinanceDataReader ì‹¬ë³¼ì´ í™˜ê²½/ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ í›„ë³´ë¥¼ ìˆœì°¨ ì‹œë„í•©ë‹ˆë‹¤.
    ë°˜í™˜: (used_symbol, series) where series index=Date, values=Adj Close
    """
    last_err = None
    for sym in symbol_candidates:
        try:
            df = fdr.DataReader(sym, start_date, end_date)
            if df is None or df.empty:
                continue
            col = 'Adj Close' if 'Adj Close' in df.columns else ('Close' if 'Close' in df.columns else None)
            if col is None:
                continue
            s = df[col].copy()
            s.index = pd.to_datetime(s.index)
            s = s.sort_index()
            s = s[~s.isna()]
            if len(s) == 0:
                continue
            return sym, s
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"ì§€ìˆ˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. candidates={symbol_candidates}, last_error={last_err}")

@st.cache_data(ttl=60 * 60 * 24, show_spinner=False)
def fetch_sp500_names():
    """
    FinanceDataReaderì˜ S&P500 listingì€ ê¸°ë³¸ì ìœ¼ë¡œ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.
    (Symbol/Name/Sector/Industryë§Œ ì œê³µë¨)
    ì—¬ê¸°ì„œëŠ” ì´ë¦„ë§Œ ë§¤í•‘ìœ¼ë¡œ ì œê³µí•˜ê³ , ì‹œê°€ì´ì•¡ì€ Yahoo Finance(yfinance)ë¡œ ë³´ê°•í•©ë‹ˆë‹¤.
    """
    try:
        listing = fdr.StockListing('S&P500')
        if listing is None or listing.empty:
            return {}
        listing = listing.copy()
        listing['Symbol'] = listing['Symbol'].astype(str).str.replace('.', '-', regex=False)
        return dict(zip(listing['Symbol'], listing['Name']))
    except Exception:
        return {}


@st.cache_data(ttl=60 * 60 * 12, show_spinner=False)
def fetch_market_caps_yahoo(tickers: tuple[str, ...]):
    """
    Yahoo Financeì—ì„œ ì‹œê°€ì´ì•¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ì…ë ¥ì€ ìºì‹œ í‚¤ ì•ˆì •ì„±ì„ ìœ„í•´ tupleë¡œ ë°›ìŠµë‹ˆë‹¤.
    """
    try:
        import yfinance as yf
    except Exception:
        return {}

    from concurrent.futures import ThreadPoolExecutor, as_completed

    symbols = [str(t).strip() for t in tickers if str(t).strip()]
    if not symbols:
        return {}

    def fetch_one(original: str):
        candidates = [original]
        # ì¼ë¶€ í‹°ì»¤ëŠ” Yahooì—ì„œ '.' í‘œê¸°ì¼ ìˆ˜ ìˆì–´ ì¶”ê°€ ì‹œë„
        if "-" in original:
            candidates.append(original.replace("-", "."))

        for sym in candidates:
            try:
                tk = yf.Ticker(sym)
                # fast_infoê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                fi = getattr(tk, "fast_info", None)
                if fi and isinstance(fi, dict):
                    mcap = fi.get("market_cap")
                    if mcap is not None:
                        return original, float(mcap)

                info = tk.info if hasattr(tk, "info") else {}
                if isinstance(info, dict):
                    mcap = info.get("marketCap")
                    if mcap is not None:
                        return original, float(mcap)
            except Exception:
                continue

        return original, None

    out: dict[str, float | None] = {}
    max_workers = min(10, max(4, len(symbols)))
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = [ex.submit(fetch_one, s) for s in symbols]
        for f in as_completed(futs):
            k, v = f.result()
            out[k] = v

    return out

def rebase_to_100(series: pd.Series) -> pd.Series:
    """ì²« ê°’ ê¸°ì¤€ 100ìœ¼ë¡œ ë¦¬ë² ì´ìŠ¤(ì •ê·œí™”)"""
    s = series.dropna()
    if len(s) == 0:
        return series
    return (series / float(s.iloc[0])) * 100.0

def build_sma50_tables_from_collector(collector: StockDataCollector):
    """
    collector.collect_sma_data() ì´í›„ collector.dataframes['sma50stock_df'] ê¸°ë°˜ìœ¼ë¡œ
    'ìµœê·¼(ì˜¤ëŠ˜ ì‹¤í–‰ ì‹œì ) ê¸°ì¤€' SMA50 ìœ„/ì•„ë˜ í‹°ì»¤ë¥¼ í‘œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    df = collector.dataframes.get('sma50stock_df', None)
    if df is None or df.empty:
        return None, None, None

    df = df.copy()
    if 'Date' not in df.columns:
        # ë°©ì–´: í˜¹ì‹œ Dateê°€ ì—†ëŠ” ê²½ìš° ì¸ë±ìŠ¤ì—ì„œ ìƒì„±
        df = df.reset_index().rename(columns={'index': 'Date'})

    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values(['Code', 'Date'])

    # í‹°ì»¤ë³„ ìµœì‹ (ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼) ìƒíƒœë§Œ ì‚¬ìš©
    latest = df.groupby('Code', as_index=False).tail(1).copy()
    asof = latest['Date'].max()

    # ì»¬ëŸ¼ ì´ë¦„ì€ SMA50/SMA50_YNë¡œ êµ¬ì„±ë¨
    yn_col = 'SMA50_YN'
    sma_col = 'SMA50'
    price_col = 'Adj Close'

    if yn_col not in latest.columns or sma_col not in latest.columns or price_col not in latest.columns:
        return asof, None, None

    latest['diff_pct'] = (latest[price_col] / latest[sma_col] - 1.0) * 100.0

    # ì´ë¦„ + ì‹œê°€ì´ì•¡ ë¶™ì´ê¸°
    names = fetch_sp500_names()
    latest['Name'] = latest['Code'].map(lambda x: names.get(str(x)))

    tickers = tuple(sorted(set(latest['Code'].astype(str).tolist())))
    mcaps = fetch_market_caps_yahoo(tickers)
    latest['MarketCap'] = latest['Code'].map(lambda x: mcaps.get(str(x)))

    # ìš”ì²­ì‚¬í•­: Date ì»¬ëŸ¼ ì œê±°
    view_cols = ['Code', 'Name', 'MarketCap', price_col, sma_col, 'diff_pct']

    above = latest[latest[yn_col] == 1][view_cols].copy()
    below = latest[latest[yn_col] == 0][view_cols].copy()

    # ê¸°ë³¸ ì •ë ¬: ì‹œê°€ì´ì•¡ ë‚´ë¦¼ì°¨ìˆœ (ì‹œê°€ì´ì•¡ì´ ì—†ìœ¼ë©´ diff_pct ì •ë ¬ë¡œ fallback)
    if above['MarketCap'].notna().any():
        above = above.sort_values('MarketCap', ascending=False, na_position='last')
    else:
        above = above.sort_values('diff_pct', ascending=False)

    if below['MarketCap'].notna().any():
        below = below.sort_values('MarketCap', ascending=False, na_position='last')
    else:
        below = below.sort_values('diff_pct', ascending=True)

    # âš ï¸ í‘œì‹œ ê°œìˆ˜(top N)ëŠ” ë Œë”ë§ ë‹¨ê³„ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆì–´ì•¼ í•˜ë¯€ë¡œ,
    # ì—¬ê¸°ì„œëŠ” ì˜ë¼ë‚´ì§€ ì•Šê³  ì „ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    above = above.reset_index(drop=True)
    below = below.reset_index(drop=True)
    return asof, above, below


def render_sma50_tables_with_sort(above_df: pd.DataFrame, below_df: pd.DataFrame, key_prefix: str = "sma50_sort"):
    """
    SMA50 ìœ„/ì•„ë˜ í…Œì´ë¸”ì„ ì‚¬ìš©ì ì„ íƒìœ¼ë¡œ ì •ë ¬í•´ì„œ í‘œì‹œí•©ë‹ˆë‹¤.
    (diff_pct, MarketCap, Adj Close ë“±)
    """
    if above_df is None or below_df is None:
        st.info("SMA50 í…Œì´ë¸” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì •ë ¬ í›„ë³´ ì»¬ëŸ¼(ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
    candidate_cols = []
    for c in ["diff_pct", "MarketCap", "Adj Close", "SMA50", "Code", "Name"]:
        if (isinstance(above_df, pd.DataFrame) and c in above_df.columns) or (isinstance(below_df, pd.DataFrame) and c in below_df.columns):
            candidate_cols.append(c)

    if not candidate_cols:
        candidate_cols = list(above_df.columns)[:1] if isinstance(above_df, pd.DataFrame) and len(above_df.columns) else ["(ì—†ìŒ)"]

    c_sort1, c_sort2, c_sort3 = st.columns([1.2, 1.0, 0.9])
    with c_sort1:
        sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", candidate_cols, index=0, key=f"{key_prefix}_by")
    with c_sort2:
        sort_dir = st.selectbox("ì •ë ¬ ë°©í–¥", ["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"], index=0, key=f"{key_prefix}_dir")
    with c_sort3:
        top_n = st.selectbox("í‘œì‹œ ê°œìˆ˜", [15, 30, 50, 100, 200, 500], index=0, key=f"{key_prefix}_n")

    ascending = (sort_dir == "ì˜¤ë¦„ì°¨ìˆœ")

    def _sort_df(df: pd.DataFrame) -> pd.DataFrame:
        if df is None or not isinstance(df, pd.DataFrame) or df.empty:
            return df
        tmp = df.copy()
        if sort_by in tmp.columns:
            # ìˆ«ìí˜• ì •ë ¬ ë³´ê°•
            if sort_by in {"diff_pct", "MarketCap", "Adj Close", "SMA50"}:
                tmp[sort_by] = pd.to_numeric(tmp[sort_by], errors="coerce")
            tmp = tmp.sort_values(sort_by, ascending=ascending, na_position="last")
        n = int(top_n)
        # ë°ì´í„°ê°€ 500 ë¯¸ë§Œì¸ ê²½ìš°ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        n = min(n, len(tmp))
        return tmp.head(n).reset_index(drop=True)

    above_s = _sort_df(above_df)
    below_s = _sort_df(below_df)

    # HTML ì €ì¥ì—ì„œë„ ë™ì¼í•˜ê²Œ ë°˜ì˜ë˜ë„ë¡ "ë§ˆì§€ë§‰ ì„ íƒ"ì„ ì„¸ì…˜ì— ì €ì¥
    st.session_state["report_sma50_view"] = {
        "key_prefix": key_prefix,
        "sort_by": sort_by,
        "sort_dir": sort_dir,
        "top_n": int(top_n),
        "updated_at": datetime.now().isoformat(),
    }

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### âœ… SMA50 ìœ„(ê°€ê²© > SMA50)")
        st.dataframe(above_s, use_container_width=True)
    with c2:
        st.markdown("#### âŒ SMA50 ì•„ë˜(ê°€ê²© < SMA50)")
        st.dataframe(below_s, use_container_width=True)


def render_sma50_diffpct_trend_from_sma_dataframes(sma_dataframes: dict, key_prefix: str = "sma50_diffpct"):
    """
    SMA50 ë°ì´í„°(sma50stock_df)ë¡œë¶€í„° diff_pct ì¶”ì´ë¥¼ ê³„ì‚°í•´,
    ê¸°ê°„ë³„(1ì£¼/1ë‹¬/3ë‹¬/6ë‹¬) diff_pct ìƒìŠ¹í­ì´ ê°€ì¥ í° Top 10 ê¸°ì—…ì˜ ì¶”ì´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    """
    if not (isinstance(sma_dataframes, dict) and sma_dataframes):
        st.info("SMA ë°ì´í„°ê°€ ì—†ì–´ diff_pct ì¶”ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = sma_dataframes.get("sma50stock_df")
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        st.info("sma50stock_dfê°€ ì—†ì–´ diff_pct ì¶”ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with st.expander("ğŸ“ˆ SMA50 diff_pct ì¶”ì´(ê¸°ê°„ë³„ Top ìƒìŠ¹ 10ê°œ)", expanded=False):
        period_map = {
            "ìµœê·¼ 1ì£¼": ("1w", 7),
            "ìµœê·¼ 1ë‹¬": ("1m", 30),
            "ìµœê·¼ 3ë‹¬": ("3m", 90),
            "ìµœê·¼ 6ë‹¬": ("6m", 180),
        }
        period_label = st.selectbox("ê¸°ê°„ ì„ íƒ", list(period_map.keys()), index=1, key=f"{key_prefix}_period")
        _, days = period_map[period_label]

        tmp = df.copy()
        # Date ì •ê·œí™”
        if "Date" in tmp.columns:
            tmp["Date"] = pd.to_datetime(tmp["Date"], errors="coerce")
        else:
            tmp = tmp.reset_index().rename(columns={"index": "Date"})
            tmp["Date"] = pd.to_datetime(tmp["Date"], errors="coerce")

        tmp = tmp.dropna(subset=["Date"]).sort_values(["Code", "Date"])

        # diff_pct ê³„ì‚°
        if "Adj Close" not in tmp.columns or "SMA50" not in tmp.columns:
            st.info("diff_pct ê³„ì‚°ì— í•„ìš”í•œ ì»¬ëŸ¼(Adj Close/SMA50)ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        tmp["Adj Close"] = pd.to_numeric(tmp["Adj Close"], errors="coerce")
        tmp["SMA50"] = pd.to_numeric(tmp["SMA50"], errors="coerce")
        tmp = tmp.dropna(subset=["Adj Close", "SMA50"])
        if tmp.empty:
            st.info("ìœ íš¨í•œ ê°€ê²©/SMA50 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        tmp["diff_pct"] = (tmp["Adj Close"] / tmp["SMA50"] - 1.0) * 100.0

        end_dt = tmp["Date"].max()
        start_dt = end_dt - pd.Timedelta(days=int(days))
        tmp_p = tmp[tmp["Date"] >= start_dt].copy()
        if tmp_p.empty:
            st.info("í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì½”ë“œë³„ ì‹œì‘/ì¢…ë£Œ diff_pct
        g = tmp_p.groupby("Code", as_index=False)
        first = g.first()[["Code", "Date", "diff_pct"]].rename(columns={"diff_pct": "start_diff_pct", "Date": "start_date"})
        last = g.last()[["Code", "Date", "diff_pct"]].rename(columns={"diff_pct": "end_diff_pct", "Date": "end_date"})
        merged = first.merge(last, on="Code", how="inner")
        merged["delta_diff_pct"] = merged["end_diff_pct"] - merged["start_diff_pct"]

        # Top 10 (ìƒìŠ¹í­ í° ìˆœ)
        top = merged.sort_values("delta_diff_pct", ascending=False).head(10).copy()
        if top.empty:
            st.info("Top 10ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì´ë¦„ ë§¤í•‘(ê°€ëŠ¥í•˜ë©´)
        names = fetch_sp500_names()
        top["Name"] = top["Code"].map(lambda x: names.get(str(x)))
        top_view = top[["Code", "Name", "start_date", "end_date", "start_diff_pct", "end_diff_pct", "delta_diff_pct"]].copy()
        for c in ["start_diff_pct", "end_diff_pct", "delta_diff_pct"]:
            top_view[c] = pd.to_numeric(top_view[c], errors="coerce").round(2)

        st.dataframe(top_view, use_container_width=True)

        # ì¶”ì´ ê·¸ë˜í”„
        top_codes = top["Code"].astype(str).tolist()
        plot_df = tmp_p[tmp_p["Code"].astype(str).isin(top_codes)].copy()
        plot_df = plot_df.sort_values(["Date", "Code"])

        fig = go.Figure()
        for code in top_codes:
            d = plot_df[plot_df["Code"].astype(str) == str(code)]
            if d.empty:
                continue
            fig.add_trace(
                go.Scatter(
                    x=d["Date"],
                    y=d["diff_pct"],
                    mode="lines",
                    name=str(code),
                )
            )
        fig.update_layout(
            height=500,
            hovermode="x unified",
            title=f"SMA50 diff_pct ì¶”ì´ - {period_label} Top 10 ìƒìŠ¹",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
        )
        fig.update_yaxes(title_text="diff_pct (%)")
        fig.update_xaxes(title_text="ë‚ ì§œ")
        st.plotly_chart(fig, use_container_width=True)

        # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ì €ì¥
        try:
            st.session_state["report_sma50_diffpct"] = {
                "period_label": period_label,
                "rows": top_view.to_dict("records"),
            }
            st.session_state["report_sma50_diffpct_fig_json"] = fig.to_json()
        except Exception:
            pass

def ensure_sma50_tables_in_session_from_cached_sma() -> bool:
    """
    ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œì—ë„ SMA zip/íŒ¨í‚¤ì§€ë¡œ ë¡œë“œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´
    SMA50 ìœ„/ì•„ë˜ í…Œì´ë¸”ì„ ì„¸ì…˜ ìƒíƒœì— ìƒì„±í•´ ë‘¡ë‹ˆë‹¤.
    """
    sma_dataframes = st.session_state.get("sma_dataframes")
    if not (isinstance(sma_dataframes, dict) and sma_dataframes):
        return False

    sig = (
        st.session_state.get("_sma_upload_sig")
        or st.session_state.get("_bundle_upload_sig")
        or ("sma_cache", st.session_state.get("sma_collector_date"), len(sma_dataframes))
    )

    already_ok = (
        st.session_state.get("_sma50_tables_sig") == sig
        and "sma50_above_df" in st.session_state
        and "sma50_below_df" in st.session_state
        and st.session_state.get("sma50_above_df") is not None
        and st.session_state.get("sma50_below_df") is not None
    )
    if already_ok:
        return True

    try:
        collector = StockDataCollector()
        collector.dataframes = sma_dataframes.copy()
        asof, above_df, below_df = build_sma50_tables_from_collector(collector)
        if above_df is None or below_df is None:
            return False

        st.session_state["sma50_asof"] = asof
        st.session_state["sma50_above_df"] = above_df
        st.session_state["sma50_below_df"] = below_df
        st.session_state["_sma50_tables_sig"] = sig
        return True
    except Exception:
        return False


def export_sma_data_zip(sma_dataframes: dict, meta: dict | None = None) -> bytes:
    """
    SMA ë°ì´í„°í”„ë ˆì„(dict)ì„ zip(bytes)ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.
    - íŒŒì¼ êµ¬ì„±: meta.json, sma15.csv, sma30.csv, sma50.csv (ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
    - pickleì„ ì“°ì§€ ì•Šì•„ ë³´ì•ˆ/í˜¸í™˜ì„± ì¸¡ë©´ì—ì„œ ì•ˆì „í•©ë‹ˆë‹¤.
    """
    meta = meta or {}
    # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    meta_out = {
        "exported_at": datetime.now().isoformat(),
        **meta,
        "keys": sorted(list(sma_dataframes.keys())),
    }

    buf = io.BytesIO()
    with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("meta.json", json.dumps(meta_out, ensure_ascii=False, indent=2))

        for k, df in sma_dataframes.items():
            if df is None or (hasattr(df, "empty") and df.empty):
                continue
            # íŒŒì¼ëª… ì•ˆì •í™”
            fname = f"{k}.csv"
            tmp = df.copy()
            # Date ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ISO ë¬¸ìì—´ë¡œ ì €ì¥(ë¡œë”© ì•ˆì •ì„±)
            if "Date" in tmp.columns:
                tmp["Date"] = pd.to_datetime(tmp["Date"], errors="coerce").dt.strftime("%Y-%m-%d")
            csv_bytes = tmp.to_csv(index=False).encode("utf-8-sig")
            zf.writestr(fname, csv_bytes)

    return buf.getvalue()


def import_sma_data_zip(file_bytes: bytes) -> tuple[dict, dict]:
    """export_sma_data_zip()ë¡œ ë§Œë“  zip(bytes)ì„ ì½ì–´ SMA ë°ì´í„°(dict)ì™€ meta(dict)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    sma = {}
    meta = {}
    buf = io.BytesIO(file_bytes)
    with zipfile.ZipFile(buf, mode="r") as zf:
        if "meta.json" in zf.namelist():
            meta = json.loads(zf.read("meta.json").decode("utf-8"))

        for name in zf.namelist():
            if not name.lower().endswith(".csv"):
                continue
            key = os.path.splitext(os.path.basename(name))[0]
            df = pd.read_csv(io.BytesIO(zf.read(name)))
            # Date ë³µì›(ê°€ëŠ¥í•œ ê²½ìš°)
            if "Date" in df.columns:
                df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
            sma[key] = df

    return sma, meta

# =========================
# ëª¨ë¸(pkl) ì—…/ë‹¤ìš´ë¡œë“œ
# =========================

def export_model_pkl_bytes(predictor: StockPredictor) -> bytes | None:
    """í˜„ì¬ ë¡œë“œ/í•™ìŠµëœ ëª¨ë¸ì„ pkl(bytes)ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤."""
    if predictor is None or predictor.model is None:
        return None
    payload = {
        "model": predictor.model,
        "feature_columns": predictor.feature_columns,
        "exported_at": datetime.now().isoformat(),
    }
    return pickle.dumps(payload)


def load_model_from_pkl_bytes(predictor: StockPredictor, file_bytes: bytes) -> bool:
    """
    ì—…ë¡œë“œí•œ pkl(bytes)ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    ì£¼ì˜: pickleì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒŒì¼ë§Œ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.
    """
    data = pickle.loads(file_bytes)

    # ìš°ë¦¬ê°€ ì €ì¥í•˜ëŠ” í¬ë§·(dict) ìš°ì„  ì§€ì›
    if isinstance(data, dict) and "model" in data:
        predictor.model = data.get("model")
        predictor.feature_columns = data.get("feature_columns")
        return predictor.model is not None

    # ì˜ˆì™¸: ëª¨ë¸ ê°ì²´ë§Œ ë°”ë¡œ ë“¤ì–´ìˆëŠ” ê²½ìš°
    predictor.model = data
    if predictor.feature_columns is None:
        predictor.feature_columns = []
    return predictor.model is not None

def export_training_bundle_zip(
    sma_dataframes: dict | None,
    model_pkl_bytes: bytes | None,
    meta: dict | None = None,
) -> bytes:
    """
    SMA ë°ì´í„° + ëª¨ë¸(pkl)ì„ í•˜ë‚˜ì˜ zipìœ¼ë¡œ ë¬¶ì–´ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    êµ¬ì„±:
      - meta.json
      - model.pkl (ìˆì„ ë•Œ)
      - sma/*.csv (ìˆì„ ë•Œ)
    """
    meta = meta or {}
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("meta.json", json.dumps({"exported_at": datetime.now().isoformat(), **meta}, ensure_ascii=False, indent=2))

        if model_pkl_bytes:
            zf.writestr("model.pkl", model_pkl_bytes)

        if sma_dataframes and isinstance(sma_dataframes, dict):
            for k, df in sma_dataframes.items():
                if df is None or (hasattr(df, "empty") and df.empty):
                    continue
                tmp = df.copy()
                if "Date" in tmp.columns:
                    tmp["Date"] = pd.to_datetime(tmp["Date"], errors="coerce").dt.strftime("%Y-%m-%d")
                zf.writestr(f"sma/{k}.csv", tmp.to_csv(index=False).encode("utf-8-sig"))

    return buf.getvalue()

def import_training_bundle_zip(file_bytes: bytes) -> tuple[bytes | None, dict, dict]:
    """
    export_training_bundle_zip()ë¡œ ë§Œë“  ë²ˆë“¤ zipì„ ë¡œë“œí•©ë‹ˆë‹¤.
    Returns:
      (model_pkl_bytes or None, sma_dataframes(dict), meta(dict))
    """
    model_bytes: bytes | None = None
    sma: dict = {}
    meta: dict = {}

    buf = io.BytesIO(file_bytes)
    with zipfile.ZipFile(buf, mode="r") as zf:
        names = zf.namelist()

        if "meta.json" in names:
            try:
                meta = json.loads(zf.read("meta.json").decode("utf-8"))
            except Exception:
                meta = {}

        # ëª¨ë¸
        if "model.pkl" in names:
            model_bytes = zf.read("model.pkl")

        # SMA: sma/*.csv ìš°ì„ , ì—†ìœ¼ë©´ ë£¨íŠ¸ì˜ *.csvë„ ìˆ˜ìš©
        csv_names = [n for n in names if n.lower().endswith(".csv")]
        for name in csv_names:
            base = os.path.basename(name)
            key = os.path.splitext(base)[0]
            # ê²½ë¡œê°€ sma/ í•˜ìœ„ì´ë©´ ê·¸ëŒ€ë¡œ key ì‚¬ìš©
            if name.replace("\\", "/").startswith("sma/"):
                pass
            else:
                # ë£¨íŠ¸ csvë„ í—ˆìš© (ë‹¨, meta.csv ê°™ì€ ê²ƒì€ ì œì™¸)
                if key.lower() == "meta":
                    continue
            try:
                df = pd.read_csv(io.BytesIO(zf.read(name)))
                if "Date" in df.columns:
                    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
                sma[key] = df
            except Exception:
                continue

    return model_bytes, sma, meta

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ ì„¤ì •")

# ëª¨ë¸ ë¡œë“œ/í•™ìŠµ ì„ íƒ
# ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©: ì´ì „ì— í•™ìŠµí•˜ì—¬ ì €ì¥ëœ ëª¨ë¸ íŒŒì¼(stock_model.pkl)ì„ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ìƒˆ ëª¨ë¸ í•™ìŠµ: S&P500 ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  RandomForest ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµí•©ë‹ˆë‹¤.
model_option = st.sidebar.radio(
    "ëª¨ë¸ ì˜µì…˜",
    ["ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©", "ìƒˆ ëª¨ë¸ í•™ìŠµ"],
    index=0,
    help="ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©: ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ìƒˆ ëª¨ë¸ í•™ìŠµ: ì²˜ìŒë¶€í„° ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
)

max_tickers = st.sidebar.slider("ë¶„ì„í•  ì£¼ì‹ ìˆ˜", 10, 500, 100)

# =========================
# SMA ë°ì´í„° (ì†ŒìŠ¤/ì—…ë¡œë“œ)
# =========================
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“¦ ì´í‰ì„ (SMA) ë°ì´í„°")

has_sma_cache = ("sma_dataframes" in st.session_state and isinstance(st.session_state["sma_dataframes"], dict) and bool(st.session_state["sma_dataframes"]))

sma_source = st.sidebar.radio(
    "SMA ë°ì´í„° ì†ŒìŠ¤",
    ["ì—…ë¡œë“œ/ìºì‹œ ì‚¬ìš©(ì¬ê³„ì‚° ì•ˆí•¨)", "ìƒˆë¡œ ìˆ˜ì§‘(ì‹œê°„ ì†Œìš”)"],
    index=0 if has_sma_cache else 1,
    help="ì—…ë¡œë“œ/ìºì‹œë¥¼ ì„ íƒí•˜ë©´ S&P500 ì´í‰ì„  ê³„ì‚°ì„ ê±´ë„ˆë›°ê³ , ì €ì¥ëœ SMA ë°ì´í„°ë¡œ ë°”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.",
)

use_uploaded_sma = (sma_source == "ì—…ë¡œë“œ/ìºì‹œ ì‚¬ìš©(ì¬ê³„ì‚° ì•ˆí•¨)")
if use_uploaded_sma and not has_sma_cache:
    st.sidebar.warning("âš ï¸ ì—…ë¡œë“œ/ìºì‹œ SMA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì—…ë¡œë“œí•˜ê±°ë‚˜, 'ìƒˆë¡œ ìˆ˜ì§‘'ì„ ì„ íƒí•˜ì„¸ìš”.")

# ëª¨ë¸ ì—…/ë‹¤ìš´ë¡œë“œ UI (ìš”ì²­í•œ ìˆœì„œìƒ SMA ì—…ë¡œë“œì™€ í•¨ê»˜ í•˜ë‹¨ì— ë°°ì¹˜)
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– ëª¨ë¸ íŒŒì¼")
st.sidebar.caption("âš ï¸ pkl ì—…ë¡œë“œëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒŒì¼ë§Œ ì‚¬ìš©í•˜ì„¸ìš”(ë³´ì•ˆìƒ pickle ìœ„í—˜).")

# ëª¨ë¸ í•™ìŠµ ì‹œì‘ ë²„íŠ¼(ìš”ì²­í•œ ì‚¬ì´ë“œë°” ìˆœì„œì— ë§ì¶¤)
start_train_clicked = False
if model_option == "ìƒˆ ëª¨ë¸ í•™ìŠµ":
    start_train_clicked = st.sidebar.button("ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary")

# íŒ¨í‚¤ì§€ zip ì—…ë¡œë“œ: ëª¨ë¸ + SMAë¥¼ í•œ ë²ˆì—
uploaded_bundle_zip = st.sidebar.file_uploader(
    "íŒ¨í‚¤ì§€ ì—…ë¡œë“œ (.zip) - ëª¨ë¸+SMA",
    type=["zip"],
    help="SMA+ëª¨ë¸ íŒ¨í‚¤ì§€(zip)ë¥¼ ì—…ë¡œë“œí•˜ë©´ ëª¨ë¸ê³¼ SMA ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì„¸ì…˜ì— ë°˜ì˜í•©ë‹ˆë‹¤.",
    key="bundle_zip_uploader",
)

if uploaded_bundle_zip is not None:
    try:
        sig = (uploaded_bundle_zip.name, uploaded_bundle_zip.size)
        prev_sig = st.session_state.get("_bundle_upload_sig")

        model_bytes, sma_loaded, meta_loaded = import_training_bundle_zip(uploaded_bundle_zip.getvalue())

        if model_bytes:
            st.session_state["uploaded_model_bytes"] = model_bytes
        if sma_loaded:
            st.session_state["sma_dataframes"] = sma_loaded
            st.session_state["sma_collector_date"] = datetime.now().date().isoformat()
            st.session_state["sma_upload_meta"] = meta_loaded

        st.session_state["_bundle_upload_sig"] = sig

        if model_bytes or sma_loaded:
            st.sidebar.success(
                f"âœ… íŒ¨í‚¤ì§€ ì—…ë¡œë“œ ì™„ë£Œ (ëª¨ë¸: {'O' if model_bytes else 'X'}, SMA: {len(sma_loaded)})"
            )
            # ì—…ë¡œë“œ ì§í›„ ë¼ë””ì˜¤/ìºì‹œ ìƒíƒœ ë°˜ì˜ì„ ìœ„í•´ 1íšŒ rerun
            if prev_sig != sig:
                st.rerun()
        else:
            st.sidebar.warning("ì—…ë¡œë“œí•œ zipì—ì„œ model.pkl ë˜ëŠ” sma/*.csv ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.sidebar.error(f"íŒ¨í‚¤ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ëª¨ë¸ ì—…ë¡œë“œ (ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œ ì—…ë¡œë“œí•œ ëª¨ë¸ ìš°ì„ )
uploaded_model_pkl = st.sidebar.file_uploader(
    "ëª¨ë¸ ì—…ë¡œë“œ (.pkl)",
    type=["pkl"],
    help="í•™ìŠµí•œ ëª¨ë¸ pklì„ ì—…ë¡œë“œí•˜ë©´ 'ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©'ì—ì„œ ì—…ë¡œë“œí•œ ëª¨ë¸ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.",
    key="model_pkl_uploader",
)

if uploaded_model_pkl is not None:
    try:
        sig = (uploaded_model_pkl.name, uploaded_model_pkl.size)
        prev_sig = st.session_state.get("_model_upload_sig")
        st.session_state["uploaded_model_bytes"] = uploaded_model_pkl.getvalue()
        st.session_state["_model_upload_sig"] = sig
        st.sidebar.success("âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ")
        if prev_sig != sig:
            st.rerun()
    except Exception as e:
        st.sidebar.error(f"ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# SMA ì—…ë¡œë“œ(ì‚¬ì´ë“œë°” ê°€ì¥ ì•„ë˜)
uploaded_sma_zip = st.sidebar.file_uploader(
    "SMA ë°ì´í„° ì—…ë¡œë“œ (.zip)",
    type=["zip"],
    help="ì´ ì•±ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ SMA ë°ì´í„° zipì„ ì—…ë¡œë“œí•˜ë©´, ë‹¤ìŒë¶€í„° SMA ê³„ì‚° ì—†ì´ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.",
    key="sma_zip_uploader",
)

if uploaded_sma_zip is not None:
    try:
        sig = (uploaded_sma_zip.name, uploaded_sma_zip.size)
        prev_sig = st.session_state.get("_sma_upload_sig")

        sma_loaded, meta_loaded = import_sma_data_zip(uploaded_sma_zip.getvalue())
        if sma_loaded:
            st.session_state["sma_dataframes"] = sma_loaded
            st.session_state["sma_collector_date"] = datetime.now().date().isoformat()
            st.session_state["sma_upload_meta"] = meta_loaded
            st.session_state["_sma_upload_sig"] = sig
            st.sidebar.success(f"âœ… SMA ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ ({len(sma_loaded)}ê°œ íŒŒì¼)")

            # ì—…ë¡œë“œ ì§í›„ ì¦‰ì‹œ has_sma_cacheë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ 1íšŒ rerun
            if prev_sig != sig:
                st.rerun()
        else:
            st.sidebar.warning("ì—…ë¡œë“œëœ zipì—ì„œ SMA CSVë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.sidebar.error(f"SMA ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ëª¨ë¸ ë° ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
predictor = StockPredictor('stock_model.pkl')

# ëª¨ë¸ ë¡œë“œ ë˜ëŠ” í•™ìŠµ
if model_option == "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©":
    # ì—…ë¡œë“œí•œ ëª¨ë¸ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if "uploaded_model_bytes" in st.session_state and st.session_state["uploaded_model_bytes"]:
        try:
            ok = load_model_from_pkl_bytes(predictor, st.session_state["uploaded_model_bytes"])
            if ok:
                st.sidebar.info("âœ… ì—…ë¡œë“œí•œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                st.sidebar.warning("âš ï¸ ì—…ë¡œë“œí•œ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì €ì¥ëœ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                if not predictor.load_model():
                    st.sidebar.warning("âš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
                    model_option = "ìƒˆ ëª¨ë¸ í•™ìŠµ"
        except Exception as e:
            st.sidebar.error(f"ì—…ë¡œë“œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            if not predictor.load_model():
                st.sidebar.warning("âš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
                model_option = "ìƒˆ ëª¨ë¸ í•™ìŠµ"
    else:
        if not predictor.load_model():
            st.sidebar.warning("âš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
            model_option = "ìƒˆ ëª¨ë¸ í•™ìŠµ"
        else:
            st.sidebar.info("âœ… ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            # ì˜ˆì¸¡ ì‹¤í–‰ í”Œë˜ê·¸ëŠ” ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ Trueë¡œ ì„¤ì •ë¨

if model_option == "ìƒˆ ëª¨ë¸ í•™ìŠµ":
    if start_train_clicked:
        # ì§„í–‰ë„ í‘œì‹œë¥¼ ìœ„í•œ ìƒíƒœ ì»¨í…Œì´ë„ˆ ìƒì„±
        progress_container = st.container()
        status_container = st.container()
        
        try:
            with status_container:
                with st.status("ğŸ”„ ëª¨ë¸ í•™ìŠµ ì§„í–‰ ì¤‘...", expanded=True) as status:
                    # 1ë‹¨ê³„: S&P500 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    st.write("ğŸ“‹ 1ë‹¨ê³„: S&P500 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
                    collector = StockDataCollector()
                    ticker_list = get_sp500_tickers()
                    st.write(f"âœ… {len(ticker_list)}ê°œ í‹°ì»¤ ìˆ˜ì§‘ ì™„ë£Œ")
                    
                    # 2ë‹¨ê³„: ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘
                    if use_uploaded_sma and "sma_dataframes" in st.session_state and st.session_state["sma_dataframes"]:
                        st.write("ğŸ“Š 2ë‹¨ê³„: ì—…ë¡œë“œí•œ SMA ë°ì´í„° ì‚¬ìš© ì¤‘... (ì¬ê³„ì‚° ì—†ìŒ)")
                        collector.dataframes = st.session_state["sma_dataframes"].copy()
                        tickers_above, tickers_below = [], []
                    else:
                        st.write(f"ğŸ“Š 2ë‹¨ê³„: {max_tickers}ê°œ ì£¼ì‹ ì´ë™í‰ê· ì„ (SMA) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                        st.write("â³ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì£¼ì‹ë‹¹ ì•½ 1-2ì´ˆ ì†Œìš”)")

                        # ì§„í–‰ë„ ë°” ìƒì„±
                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        def update_progress(value):
                            progress_bar.progress(value)

                        def update_status(text):
                            status_text.text(text)

                        tickers_above, tickers_below = collector.collect_sma_data(
                            ticker_list,
                            max_tickers,
                            progress_callback=update_progress,
                            status_callback=update_status
                        )
                        progress_bar.progress(1.0)
                        status_text.text(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ìœ„: {len(tickers_above)}, ì•„ë˜: {len(tickers_below)})")

                    # SMA50 ìœ„/ì•„ë˜ ê¸°ì—… ëª©ë¡ í‘œì‹œ + ì„¸ì…˜ ì €ì¥ (ì—¬ê¸°ì„œ 1íšŒë§Œ ë Œë”ë§)
                    asof, above_df, below_df = build_sma50_tables_from_collector(collector)
                    if above_df is not None and below_df is not None:
                        st.session_state['sma50_asof'] = asof
                        st.session_state['sma50_above_df'] = above_df
                        st.session_state['sma50_below_df'] = below_df
                        # SMA ë°ì´í„°ë„ ì„¸ì…˜ì— ì €ì¥ (ë‹¤ìš´ë¡œë“œ/ì˜ˆì¸¡ ì¬ì‚¬ìš©)
                        st.session_state["sma_dataframes"] = collector.dataframes.copy()
                        st.session_state["sma_collector_date"] = datetime.now().date().isoformat()

                        st.markdown("---")
                        st.subheader("ğŸ“Œ (ì˜¤ëŠ˜/ìµœê·¼ ê±°ë˜ì¼ ê¸°ì¤€) SMA50 ìœ„/ì•„ë˜ ê¸°ì—… ëª©ë¡")
                        st.caption(f"ê¸°ì¤€ì¼: {asof.strftime('%Y-%m-%d') if hasattr(asof, 'strftime') else str(asof)[:10]}")
                        render_sma50_tables_with_sort(above_df, below_df, key_prefix="sma50_train")
                        # diff_pct ì¶”ì´(Top ìƒìŠ¹) ì¶”ê°€
                        render_sma50_diffpct_trend_from_sma_dataframes(st.session_state.get("sma_dataframes"), key_prefix="sma50_diffpct_train")

                        # ìˆ˜ì§‘ ì§í›„ ë°”ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ë³¸ë¬¸ì—ë„ ë²„íŠ¼ ì œê³µ
                        try:
                            sma_zip = export_sma_data_zip(
                                st.session_state["sma_dataframes"],
                                meta={
                                    "source": "collected",
                                    "max_tickers": max_tickers,
                                    "windows": getattr(collector, "list_window", None),
                                },
                            )
                            st.download_button(
                                label="â¬‡ï¸ ìˆ˜ì§‘í•œ SMA ë°ì´í„° ë‹¤ìš´ë¡œë“œ(.zip)",
                                data=sma_zip,
                                file_name=f"sma_data_{datetime.now().date().isoformat()}_{max_tickers}.zip",
                                mime="application/zip",
                                help="í•œ ë²ˆ ìˆ˜ì§‘í•œ SMA ë°ì´í„°ë¥¼ ì €ì¥í•´ë‘ë©´, ë‹¤ìŒì—ëŠ” ì—…ë¡œë“œ/ìºì‹œë¡œ ì¬ê³„ì‚° ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                            )
                        except Exception as e:
                            st.warning(f"SMA zip ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    
                    # 3ë‹¨ê³„: íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„
                    st.write("ğŸ¯ 3ë‹¨ê³„: íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
                    # ê¸°ë³¸ê°’(for_prediction=False)ì´ë¯€ë¡œ í‚¤ì›Œë“œ ì¸ìë¥¼ ë„˜ê¸°ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
                    # (ì¼ë¶€ í™˜ê²½/ìºì‹œì—ì„œ êµ¬ë²„ì „ ëª¨ë“ˆì´ ë¡œë“œë  ë•Œ í˜¸í™˜ì„± ì´ìŠˆ ë°©ì§€)
                    spy = collector.prepare_target_data('IXIC')
                    st.write("âœ… íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                    
                    # 4ë‹¨ê³„: íŠ¹ì„± ë°ì´í„° ì¶”ê°€
                    st.write("ğŸ”§ 4ë‹¨ê³„: ê¸°ìˆ ì  ì§€í‘œ ë° ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ ì¤‘...")
                    spy = collector.add_features(spy)
                    st.write("âœ… íŠ¹ì„± ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
                    
                    # 5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì¤€ë¹„
                    st.write("ğŸ“¦ 5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
                    X = build_feature_matrix(spy)
                    y = spy['Target']
                    st.write(f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ìƒ˜í”Œ ìˆ˜: {len(X)}, íŠ¹ì„± ìˆ˜: {len(X.columns)})")
                    
                    # 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
                    st.write("ğŸ¤– 6ë‹¨ê³„: RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...")
                    st.write("â³ ì´ ê³¼ì •ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (2000ê°œ íŠ¸ë¦¬ ìƒì„±, ìˆ˜ë¶„ ì†Œìš”)")
                    
                    # ëª¨ë¸ í•™ìŠµ ì§„í–‰ë„ í‘œì‹œ
                    train_progress = st.progress(0)
                    train_status = st.empty()
                    
                    def update_train_progress(value):
                        train_progress.progress(value)
                    
                    def update_train_status(text):
                        train_status.text(text)
                    
                    train_score, test_score, oob_score = predictor.train_model(
                        X, y,
                        progress_callback=update_train_progress,
                        status_callback=update_train_status
                    )
                    
                    train_progress.progress(1.0)
                    train_status.text("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                    
                    # 7ë‹¨ê³„: ëª¨ë¸ ì €ì¥
                    st.write("ğŸ’¾ 7ë‹¨ê³„: ëª¨ë¸ ì €ì¥ ì¤‘...")
                    predictor.save_model()
                    st.write("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

                    # í•™ìŠµ ê²°ê³¼/ì•„í‹°íŒ©íŠ¸ëŠ” ì„¸ì…˜ì— ì €ì¥ (ë‹¤ìš´ë¡œë“œ í´ë¦­ rerunì—ë„ í™”ë©´ ìœ ì§€)
                    st.session_state["train_completed"] = True
                    st.session_state["train_scores"] = {
                        "train_score": float(train_score),
                        "test_score": float(test_score),
                        "oob_score": float(oob_score),
                    }
                    st.session_state["trained_model_bytes"] = export_model_pkl_bytes(predictor)
                    
                    # í•™ìŠµ ì‹œ ìˆ˜ì§‘í•œ ì´í‰ì„  ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì˜ˆì¸¡ ì‹œ ì¬ì‚¬ìš©)
                    today_str = datetime.now().date().isoformat()
                    st.session_state['sma_dataframes'] = collector.dataframes.copy()
                    st.session_state['sma_collector_date'] = today_str
                    st.write("âœ… ì´í‰ì„  ë°ì´í„° ì €ì¥ ì™„ë£Œ (ì˜ˆì¸¡ ì‹œ ì¬ì‚¬ìš©)")
                    
                    # í•™ìŠµ ì™„ë£Œ í›„ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° (ì˜ˆì¸¡ ë°ì´í„° ì‚¬ìš©)
                    st.write("ğŸ“Š ì˜ˆì¸¡ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° ì¤‘...")
                    try:
                        # ì˜ˆì¸¡ìš© ìµœì‹  ë°ì´í„° ì¤€ë¹„
                        sma_dataframes = collector.dataframes.copy()
                        X_pred, spy_pred = prepare_prediction_data(
                            progress_callback=None,
                            status_callback=None,
                            sma_dataframes=sma_dataframes
                        )
                        # ì—…ë¡œë“œ/ê¸°ì¡´ ëª¨ë¸ê³¼ feature mismatch ë°©ì§€: Seriesë¡œ ì „ë‹¬(ì»¬ëŸ¼ align ê°€ëŠ¥)
                        current_prob = predictor.get_current_probability(X_pred.iloc[-1])
                        
                        # ì˜ˆì¸¡ í™•ë¥ ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (í•˜ë‹¨ í‘œì‹œìš©)
                        st.session_state['training_prediction_prob'] = current_prob
                        st.session_state['training_prediction_X'] = X_pred
                        st.session_state['training_prediction_spy'] = spy_pred
                        st.write(f"âœ… ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° ì™„ë£Œ: {current_prob*100:.2f}%")
                    except Exception as e:
                        st.warning(f"ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    
                    status.update(label="âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!", state="complete")
            
            # í•™ìŠµ ê²°ê³¼ í‘œì‹œ
            st.sidebar.success("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            st.sidebar.metric("í…ŒìŠ¤íŠ¸ ì •í™•ë„", f"{test_score:.3f}")
            st.sidebar.metric("OOB ì •í™•ë„", f"{oob_score:.3f}")
            
            # í•™ìŠµ ê²°ê³¼ ìƒì„¸ í‘œì‹œ
            st.success("ğŸ‰ ëª¨ë¸ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í›ˆë ¨ ì„¸íŠ¸ ì •í™•ë„", f"{train_score:.3f}")
            with col2:
                st.metric("í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„", f"{test_score:.3f}")
            with col3:
                st.metric("OOB ì •í™•ë„", f"{oob_score:.3f}")

            # ë‹¤ìš´ë¡œë“œ(íŒ¨í‚¤ì§€): SMA + ëª¨ë¸ì„ í•œ ë²ˆì—
            bundle = export_training_bundle_zip(
                sma_dataframes=st.session_state.get("sma_dataframes"),
                model_pkl_bytes=st.session_state.get("trained_model_bytes"),
                meta={
                    "type": "bundle",
                    "max_tickers": max_tickers,
                    "note": "SMA(csv) + model(pkl) bundle",
                },
            )
            st.download_button(
                label="â¬‡ï¸ SMA+ëª¨ë¸ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ(.zip)",
                data=bundle,
                file_name=f"bundle_{datetime.now().date().isoformat()}_{max_tickers}.zip",
                mime="application/zip",
                help="SMA ë°ì´í„°ì™€ í•™ìŠµëœ ëª¨ë¸ì„ í•œ ë²ˆì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. (ë‹¤ìš´ë¡œë“œ í´ë¦­ ì‹œ rerunë˜ë”ë¼ë„ ê²°ê³¼ í™”ë©´ì€ ìœ ì§€ë©ë‹ˆë‹¤.)",
            )
            
            # í•™ìŠµ í›„ ì˜ˆì¸¡ í™•ë¥  í‘œì‹œ (í•˜ë‹¨)
            if 'training_prediction_prob' in st.session_state:
                st.markdown("---")
                st.subheader("ğŸ“Š ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡ í™•ë¥ ")
                training_prob = st.session_state['training_prediction_prob']
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "í˜„ì¬ ìƒìŠ¹ í™•ë¥ ",
                        f"{training_prob*100:.2f}%",
                        delta=f"{(training_prob-0.5)*100:.2f}%p",
                        delta_color="normal" if training_prob > 0.5 else "inverse"
                    )
                
                with col2:
                    if 'training_prediction_spy' in st.session_state:
                        training_spy = st.session_state['training_prediction_spy']
                        last_date = training_spy.index[-1]
                        last_date_str = str(last_date)[:10] if hasattr(last_date, '__str__') else str(last_date)
                        st.metric("ë°ì´í„° ê¸°ì¤€ì¼", last_date_str)
                
                # í™•ë¥  í•´ì„
                if training_prob >= 0.7:
                    st.success(f"ğŸŸ¢ ë†’ì€ ìƒìŠ¹ í™•ë¥  ({training_prob*100:.1f}%) - ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸")
                elif training_prob >= 0.6:
                    st.info(f"ğŸ”µ ì¤‘ê°„ ìƒìŠ¹ í™•ë¥  ({training_prob*100:.1f}%) - ì•½í•œ ë§¤ìˆ˜ ì‹ í˜¸")
                elif training_prob >= 0.4:
                    st.warning(f"ğŸŸ¡ ì¤‘ë¦½ ({training_prob*100:.1f}%) - ê´€ë§ ê¶Œì¥")
                else:
                    st.error(f"ğŸ”´ ë‚®ì€ ìƒìŠ¹ í™•ë¥  ({training_prob*100:.1f}%) - ë§¤ë„ ê³ ë ¤")
                
                # ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥  (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)
                if 'training_prediction_X' in st.session_state:
                    training_X = st.session_state['training_prediction_X']
                    prob_history_recent = predictor.get_probability_history(training_X, days=5)
                    
                    if prob_history_recent is not None and len(prob_history_recent) > 0:
                        st.markdown("---")
                        st.subheader("ğŸ“… ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥  (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)")
                        
                        # get_probability_historyëŠ” k=0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ:
                        # - ì²« ë²ˆì§¸ í–‰: ê°€ì¥ ìµœê·¼ ë‚ ì§œ (X.iloc[-1])
                        # - ë‹¤ì„¯ ë²ˆì§¸ í–‰: 4ì¼ ì „ ë‚ ì§œ (X.iloc[-5])
                        # head(5)ë¡œ ìµœì‹  5ì¼ì„ ê°€ì ¸ì˜¤ë©´ ì´ë¯¸ ìµœì‹  ë‚ ì§œê°€ ì²« ë²ˆì§¸ í–‰ì— ìˆìŒ
                        # ì—­ìˆœ ì •ë ¬í•˜ì—¬ ì™¼ìª½ë¶€í„° ì˜¤ë˜ëœ ë‚ ì§œ â†’ ìµœì‹  ë‚ ì§œ ìˆœìœ¼ë¡œ í‘œì‹œ
                        recent_5days = prob_history_recent.head(5).copy()
                        # ì—­ìˆœ ì •ë ¬ (ì™¼ìª½: ì˜¤ë˜ëœ ë‚ ì§œ, ì˜¤ë¥¸ìª½: ìµœì‹  ë‚ ì§œ)
                        recent_5days = recent_5days.iloc[::-1].copy()
                        recent_5days['Probability'] = recent_5days['Probability'] * 100
                        recent_5days['ë‚ ì§œ'] = recent_5days.index.strftime('%Y-%m-%d')
                        recent_5days['ì˜ˆì¸¡ í™•ë¥  (%)'] = recent_5days['Probability']
                        
                        # ì‹¤ì œ ì‚¬ìš©í•œ ë°ì´í„°ë„ í•¨ê»˜ í‘œì‹œ
                        display_df = recent_5days[['ë‚ ì§œ', 'ì˜ˆì¸¡ í™•ë¥  (%)']].copy()
                        # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ìµœê·¼ 5ì¼ ìƒìŠ¹ í™•ë¥  ì €ì¥
                        try:
                            st.session_state["report_recent5_up"] = [
                                {"date": str(r.get("ë‚ ì§œ")), "prob": float(r.get("ì˜ˆì¸¡ í™•ë¥  (%)")) / 100.0}
                                for r in display_df.to_dict("records")
                                if r.get("ë‚ ì§œ") is not None and r.get("ì˜ˆì¸¡ í™•ë¥  (%)") is not None
                            ]
                        except Exception:
                            pass
                        
                        # 5ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚ ì§œë³„ í™•ë¥  í‘œì‹œ
                        cols = st.columns(5)
                        for idx, (date_idx, row) in enumerate(display_df.iterrows()):
                            with cols[idx]:
                                prob_value = row['ì˜ˆì¸¡ í™•ë¥  (%)']
                                date_str = row['ë‚ ì§œ']
                                
                                # í™•ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                                if prob_value >= 70:
                                    delta_color = "normal"
                                elif prob_value >= 60:
                                    delta_color = "normal"
                                elif prob_value >= 40:
                                    delta_color = "off"
                                else:
                                    delta_color = "inverse"
                                
                                # ì´ì „ ë‚ ì§œì™€ì˜ ì°¨ì´ ê³„ì‚°
                                delta = None
                                if idx < len(display_df) - 1:
                                    prev_prob = display_df.iloc[idx + 1]['ì˜ˆì¸¡ í™•ë¥  (%)']
                                    delta = prob_value - prev_prob
                                
                                st.metric(
                                    label=date_str,
                                    value=f"{prob_value:.2f}%",
                                    delta=f"{delta:.2f}%p" if delta is not None else None,
                                    delta_color=delta_color if delta is not None else "off"
                                )
                        
                        # ì‚¬ìš©í•œ ë°ì´í„° ìƒì„¸ ë³´ê¸°
                        with st.expander("ğŸ“Š ì‚¬ìš©í•œ ë°ì´í„° ìƒì„¸ ë³´ê¸°"):
                            st.write("**ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°ì— ì‚¬ìš©í•œ ë°ì´í„°:**")
                            
                            # ê° ë‚ ì§œë³„ë¡œ ì‚¬ìš©í•œ feature ë°ì´í„° í‘œì‹œ
                            for date_idx in recent_5days.index:
                                date_str = str(date_idx)[:10]
                                st.write(f"### {date_str}")
                                
                                # í•´ë‹¹ ë‚ ì§œì˜ feature ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                                if date_idx in training_X.index:
                                    feature_data = training_X.loc[date_idx]
                                    feature_df = pd.DataFrame({
                                        'Feature': feature_data.index,
                                        'Value': feature_data.values
                                    })
                                    st.dataframe(feature_df, use_container_width=True, hide_index=True)
                                
                                # í•´ë‹¹ ë‚ ì§œì˜ ì£¼ê°€ ì •ë³´ë„ í‘œì‹œ
                                if 'training_prediction_spy' in st.session_state:
                                    training_spy = st.session_state['training_prediction_spy']
                                    if date_idx in training_spy.index:
                                        price_info = training_spy.loc[date_idx]
                                        price_cols = st.columns(4)
                                        with price_cols[0]:
                                            st.metric("ì¢…ê°€", f"${price_info.get('Close', 0):,.2f}")
                                        with price_cols[1]:
                                            if 'rsi' in price_info:
                                                st.metric("RSI", f"{price_info['rsi']:.2f}")
                                        with price_cols[2]:
                                            if 'vix' in price_info:
                                                st.metric("VIX", f"{price_info['vix']:.2f}")
                                        with price_cols[3]:
                                            if 'Change20day' in price_info:
                                                st.metric("Change20day", f"{price_info['Change20day']:.2f}%")
                                st.markdown("---")

                    # ìµœê·¼ 5ì¼ ì•„ë˜ì— ì¶”ê°€ ì‹œê°í™”(í™•ë¥  ì¶”ì´/ì§€ìˆ˜ ë¹„êµ)
                    st.markdown("---")
                    st.subheader("ğŸ“ˆ í™•ë¥  ì¶”ì´ ê·¸ë˜í”„ (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)")

                    prob_history = predictor.get_probability_history(training_X, days=min(500, len(training_X)))
                    if prob_history is not None and len(prob_history) > 0:
                        prob_history = prob_history.sort_index()
                        prob_dates = prob_history.index

                        # ì£¼ê°€ ë°ì´í„°(ë‚˜ìŠ¤ë‹¥)ë„ í•¨ê»˜ í‘œì‹œ
                        try:
                            price_data = fdr.DataReader('IXIC', prob_dates[0], prob_dates[-1])
                            price_aligned = price_data.reindex(prob_dates, method='nearest')
                        except Exception:
                            price_aligned = None

                        fig = make_subplots(specs=[[{"secondary_y": True}]])
                        fig.add_trace(
                            go.Scatter(
                                x=prob_dates,
                                y=prob_history['Probability'] * 100,
                                name="ìƒìŠ¹ í™•ë¥  (%)",
                                line=dict(color='skyblue', width=2),
                                mode='lines'
                            ),
                            secondary_y=False
                        )
                        fig.add_hline(
                            y=50,
                            line_dash="dash",
                            line_color="gray",
                            opacity=0.5,
                            annotation_text="ê¸°ì¤€ì„  (50%)",
                            secondary_y=False
                        )
                        if price_aligned is not None and len(price_aligned) > 0:
                            col = 'Adj Close' if 'Adj Close' in price_aligned.columns else ('Close' if 'Close' in price_aligned.columns else None)
                            if col is not None and not price_aligned[col].isna().all():
                                fig.add_trace(
                                    go.Scatter(
                                        x=prob_dates,
                                        y=price_aligned[col],
                                        name="IXIC ê°€ê²©",
                                        line=dict(color='red', width=1, dash='dot'),
                                        opacity=0.5
                                    ),
                                    secondary_y=True
                                )

                        fig.update_xaxes(title_text="ë‚ ì§œ")
                        fig.update_yaxes(title_text="ìƒìŠ¹ í™•ë¥  (%)", secondary_y=False, range=[0, 100])
                        fig.update_yaxes(title_text="ì£¼ê°€ (USD)", secondary_y=True)
                        fig.update_layout(
                            title="ì£¼ê°€ ìƒìŠ¹ í™•ë¥  ì¶”ì´ ë° IXIC ê°€ê²© (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)",
                            height=600,
                            hovermode='x unified',
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆì–´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                    st.subheader("ğŸ“Š ìµœê·¼ 5ë…„: ë‚˜ìŠ¤ë‹¥ / S&P500 / ë‹¤ìš°ì¡´ìŠ¤ vs ì˜ˆì¸¡ í™•ë¥  (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)")
                    try:
                        prob_all = predictor.get_probability_history(training_X, days=len(training_X))
                        if prob_all is None or len(prob_all) == 0:
                            st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            prob_all = prob_all.sort_index()
                            end_dt = prob_all.index.max()
                            start_dt = end_dt - pd.DateOffset(years=5)
                            prob_5y = prob_all.loc[prob_all.index >= start_dt].copy()
                            prob_5y['prob_pct'] = prob_5y['Probability'] * 100.0

                            start_fetch = start_dt.date()
                            end_fetch = (end_dt.date() + timedelta(days=1))

                            nas_sym, nas = fetch_index_adj_close(['IXIC', '^IXIC'], start_fetch, end_fetch)
                            sp_sym, sp = fetch_index_adj_close(['US500', 'SPX', '^GSPC'], start_fetch, end_fetch)
                            dow_sym, dow = fetch_index_adj_close(['DJI', '^DJI'], start_fetch, end_fetch)

                            idx = prob_5y.index
                            nas_a = nas.reindex(idx, method='ffill')
                            sp_a = sp.reindex(idx, method='ffill')
                            dow_a = dow.reindex(idx, method='ffill')

                            nas_r = rebase_to_100(nas_a)
                            sp_r = rebase_to_100(sp_a)
                            dow_r = rebase_to_100(dow_a)

                            fig2 = make_subplots(specs=[[{"secondary_y": True}]])
                            fig2.add_trace(
                                go.Scatter(
                                    x=idx,
                                    y=prob_5y['prob_pct'],
                                    name="ì˜ˆì¸¡ ìƒìŠ¹ í™•ë¥ (%)",
                                    line=dict(color='skyblue', width=2),
                                    mode='lines'
                                ),
                                secondary_y=False
                            )
                            fig2.add_trace(
                                go.Scatter(
                                    x=idx,
                                    y=nas_r,
                                    name=f"ë‚˜ìŠ¤ë‹¥({nas_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                    line=dict(color='#FF4B4B', width=1.5),
                                    mode='lines'
                                ),
                                secondary_y=True
                            )
                            fig2.add_trace(
                                go.Scatter(
                                    x=idx,
                                    y=sp_r,
                                    name=f"S&P500({sp_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                    line=dict(color='#2ECC71', width=1.5),
                                    mode='lines'
                                ),
                                secondary_y=True
                            )
                            fig2.add_trace(
                                go.Scatter(
                                    x=idx,
                                    y=dow_r,
                                    name=f"ë‹¤ìš°({dow_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                    line=dict(color='#F1C40F', width=1.5),
                                    mode='lines'
                                ),
                                secondary_y=True
                            )

                            fig2.update_xaxes(title_text="ë‚ ì§œ")
                            fig2.update_yaxes(title_text="ì˜ˆì¸¡ ìƒìŠ¹ í™•ë¥  (%)", secondary_y=False, range=[0, 100])
                            fig2.update_yaxes(title_text="ì§€ìˆ˜ ë¦¬ë² ì´ìŠ¤ (ì²«ê°’=100)", secondary_y=True)
                            fig2.update_layout(
                                height=650,
                                hovermode='x unified',
                                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
                                title="ìµœê·¼ 5ë…„ ì§€ìˆ˜ ì›€ì§ì„(ë¦¬ë² ì´ìŠ¤)ê³¼ ì˜ˆì¸¡ í™•ë¥  ë¹„êµ (ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜)"
                            )
                            st.plotly_chart(fig2, use_container_width=True)
                    except Exception as e:
                        st.warning(f"ìµœê·¼ 5ë…„ ë¹„êµ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.exception(e)

    # ë‹¤ìš´ë¡œë“œ/ìƒˆë¡œê³ ì¹¨ ë“± rerun ì´í›„ì—ë„ í•™ìŠµ ê²°ê³¼ë¥¼ ê³„ì† ë³´ì—¬ì£¼ê¸°
    if st.session_state.get("train_completed", False) and "train_scores" in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“¦ í•™ìŠµ ê²°ê³¼(ì„¸ì…˜ ìœ ì§€)")
        scores = st.session_state["train_scores"]
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("í›ˆë ¨ ì„¸íŠ¸ ì •í™•ë„", f"{scores.get('train_score', 0):.3f}")
        with c2:
            st.metric("í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„", f"{scores.get('test_score', 0):.3f}")
        with c3:
            st.metric("OOB ì •í™•ë„", f"{scores.get('oob_score', 0):.3f}")

        bundle = export_training_bundle_zip(
            sma_dataframes=st.session_state.get("sma_dataframes"),
            model_pkl_bytes=st.session_state.get("trained_model_bytes"),
            meta={
                "type": "bundle",
                "max_tickers": max_tickers,
                "note": "SMA(csv) + model(pkl) bundle",
            },
        )
        st.download_button(
            label="â¬‡ï¸ SMA+ëª¨ë¸ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ(.zip)",
            data=bundle,
            file_name=f"bundle_{datetime.now().date().isoformat()}_{max_tickers}.zip",
            mime="application/zip",
        )

# ë©”ì¸ ì½˜í…ì¸ 
# "ìƒˆ ëª¨ë¸ í•™ìŠµ" ì„ íƒ ì‹œì—ëŠ” ë©”ì¸ ì½˜í…ì¸ ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ì‚¬ì´ë“œë°” ë²„íŠ¼ë§Œ í‘œì‹œ)
if model_option == "ìƒˆ ëª¨ë¸ í•™ìŠµ":
    # ì‚¬ì´ë“œë°”ì— "ëª¨ë¸ í•™ìŠµ ì‹œì‘" ë²„íŠ¼ì´ í‘œì‹œë¨
    st.markdown("<div style='height: 14px;'></div>", unsafe_allow_html=True)
    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ 'ëª¨ë¸ í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
elif predictor.model is not None:
    # Hero íƒ€ì´í‹€ê³¼ ë³¸ë¬¸(ë²„íŠ¼/ì„¹ì…˜) ê°„ ê°„ê²©
    st.markdown("<div style='height: 14px;'></div>", unsafe_allow_html=True)
    # ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œì—ëŠ” ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ë§Œ ì˜ˆì¸¡ ì‹¤í–‰
    if model_option == "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©":
        # ìºì‹œê°€ ìˆìœ¼ë©´(ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€) ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì•„ë„ ê·¸ë˜í”„ë¥¼ ë³¼ ìˆ˜ ìˆê²Œ í•¨
        today_str = datetime.now().date().isoformat()
        cache_key = f"spy_data_{max_tickers}"
        cache_date_key = f"cache_date_{max_tickers}"
        has_cache = (
            cache_key in st.session_state and
            cache_date_key in st.session_state and
            st.session_state[cache_date_key] == today_str
        )

        # ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆëŠ”ì§€ í™•ì¸
        button_clicked = st.button("ğŸ”„ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°", type="primary", key="predict_button")
        
        if button_clicked:
            st.session_state.run_prediction = True
        
        if not st.session_state.get('run_prediction', False) and not has_cache:
            st.info("ğŸ’¡ ìœ„ì˜ 'ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì˜ˆì¸¡ì„ ì‹œì‘í•˜ì„¸ìš”. (ì´ë¯¸ ê³„ì‚°ëœ ìºì‹œê°€ ìˆìœ¼ë©´ ë°”ë¡œ í‘œì‹œë©ë‹ˆë‹¤.)")
            st.stop()
    
    # í˜„ì¬ í™•ë¥  ê³„ì‚°
    st.subheader("ğŸ“Š í˜„ì¬ ì˜ˆì¸¡ í™•ë¥ ")

    # ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œì—ë„ SMA(zip/íŒ¨í‚¤ì§€) ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë™ì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±/í‘œê¸°
    ensure_sma50_tables_in_session_from_cached_sma()
    if 'sma50_above_df' in st.session_state and 'sma50_below_df' in st.session_state:
        if st.session_state.get('sma50_above_df') is not None and st.session_state.get('sma50_below_df') is not None:
            asof = st.session_state.get('sma50_asof', None)
            st.markdown("---")
            st.subheader("ğŸ“Œ (ì˜¤ëŠ˜/ìµœê·¼ ê±°ë˜ì¼ ê¸°ì¤€) SMA50 ìœ„/ì•„ë˜ ê¸°ì—… ëª©ë¡")
            if asof is not None:
                st.caption(f"ê¸°ì¤€ì¼: {asof.strftime('%Y-%m-%d') if hasattr(asof, 'strftime') else str(asof)[:10]}")
            render_sma50_tables_with_sort(
                st.session_state.get('sma50_above_df'),
                st.session_state.get('sma50_below_df'),
                key_prefix="sma50_main",
            )
            # diff_pct ì¶”ì´(Top ìƒìŠ¹) ì¶”ê°€
            render_sma50_diffpct_trend_from_sma_dataframes(st.session_state.get("sma_dataframes"), key_prefix="sma50_diffpct_main")
    
    try:
        # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ìºì‹± (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        cache_key = f"spy_data_{max_tickers}"
        cache_date_key = f"cache_date_{max_tickers}"
        
        # ìºì‹œëœ ë°ì´í„°ê°€ ìˆê³  ì˜¤ëŠ˜ ë‚ ì§œì™€ ê°™ìœ¼ë©´ ì¬ì‚¬ìš©
        today_str = datetime.now().date().isoformat()
        use_cache = (
            cache_key in st.session_state and 
            cache_date_key in st.session_state and
            st.session_state[cache_date_key] == today_str
        )
        
        if use_cache:
            # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©
            spy = st.session_state[cache_key]
            X = st.session_state.get(f"{cache_key}_X", None)
            if X is None:
                X = build_feature_matrix(spy)
            
            # ìºì‹œ ì‚¬ìš© ì‹œì—ëŠ” "í•œ ë²ˆë§Œ" í”Œë˜ê·¸ë¥¼ ë‚´ë¦½ë‹ˆë‹¤ (ë§¤ ì‹¤í–‰ë§ˆë‹¤ ë‚´ë¦¬ë©´ rerun ë£¨í”„ ë°œìƒ ê°€ëŠ¥)
            if model_option == "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©" and st.session_state.get('run_prediction', False):
                st.session_state.run_prediction = False
        else:
            # ì˜ˆì¸¡ ì‹œì—ëŠ” ìµœì‹  ë°ì´í„°ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì™€ì•¼ í•¨
            # Train ë°ì´í„°ëŠ” 1ì›” 2ì¼ê¹Œì§€ì§€ë§Œ, ì˜ˆì¸¡ ì‹œì—ëŠ” í˜„ì¬ ë‚ ì§œê¹Œì§€ ë°ì´í„° í•„ìš”
            # ì°¸ì¡° ì½”ë“œ: k1 = fdr.DataReader('IXIC', '2015-01-01', a) - ì—¬ê¸°ì„œ aëŠ” í˜„ì¬ ë‚ ì§œ
            
            # í•™ìŠµ ì‹œ ìˆ˜ì§‘í•œ ì´í‰ì„  ë°ì´í„° ì¬ì‚¬ìš© (ìˆìœ¼ë©´)
            sma_dataframes = None
            if 'sma_dataframes' in st.session_state and 'sma_collector_date' in st.session_state:
                if st.session_state['sma_collector_date'] == today_str:
                    sma_dataframes = st.session_state['sma_dataframes']
            
            # ì§„í–‰ë„ í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
            progress_container = st.container()
            status_container = st.container()
            
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            # ì§„í–‰ë„ ì½œë°± í•¨ìˆ˜ ì •ì˜
            def update_progress(value):
                progress_bar.progress(value)
            
            def update_status(text):
                status_text.text(text)
            
            # ë°ì´í„° ìˆ˜ì§‘ (ì§„í–‰ë„ í‘œì‹œ, í•™ìŠµ ì‹œ ìˆ˜ì§‘í•œ ì´í‰ì„  ë°ì´í„° ì¬ì‚¬ìš©)
            X, spy = prepare_prediction_data(
                progress_callback=update_progress,
                status_callback=update_status,
                sma_dataframes=sma_dataframes
            )
            
            # ì§„í–‰ë„ ì™„ë£Œ
            progress_bar.progress(1.0)
            status_text.text("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            
            # ì„¸ì…˜ ìƒíƒœì— ìºì‹±
            st.session_state[cache_key] = spy
            st.session_state[f"{cache_key}_X"] = X
            st.session_state[cache_date_key] = today_str
            
            # ì˜ˆì¸¡ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹ (ë§¤ ì‹¤í–‰ë§ˆë‹¤ ë‚´ë¦¬ë©´ rerun ë£¨í”„ ë°œìƒ ê°€ëŠ¥)
            if model_option == "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©" and st.session_state.get('run_prediction', False):
                st.session_state.run_prediction = False
        
        # ìµœì‹  íŠ¹ì„± ë°ì´í„° (ë§ˆì§€ë§‰ í–‰ì´ ìµœì‹  ë°ì´í„°)
        # ì°¸ì¡° ì½”ë“œ: X9.iloc[-1] - ë§ˆì§€ë§‰ í–‰ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
        
        # ì‹¤ì œ ìµœì‹  ê±°ë˜ì¼ í™•ì¸ (FinanceDataReaderì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
        try:
            latest_data = fdr.DataReader('IXIC', end_date=datetime.now().date() + timedelta(days=1))
            if len(latest_data) > 0:
                actual_last_date = latest_data.index[-1]
                # ì£¼ë§/ê³µíœ´ì¼ ì œì™¸í•˜ê³  ì‹¤ì œ ê±°ë˜ì¼ í™•ì¸
                actual_last_date_str = actual_last_date.strftime('%Y-%m-%d') if hasattr(actual_last_date, 'strftime') else str(actual_last_date)[:10]
            else:
                actual_last_date_str = str(spy.index[-1])[:10]
        except:
            actual_last_date_str = str(spy.index[-1])[:10]
        
        # í˜„ì¬ í™•ë¥  ê³„ì‚°
        # ì—…ë¡œë“œ/ê¸°ì¡´ ëª¨ë¸ê³¼ feature mismatch ë°©ì§€: Seriesë¡œ ì „ë‹¬(ì»¬ëŸ¼ align ê°€ëŠ¥)
        current_prob = predictor.get_current_probability(X.iloc[-1])
        # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ì„¸ì…˜ ìƒíƒœ ì €ì¥
        try:
            st.session_state["report_current_up_prob"] = float(current_prob) if current_prob is not None else None
        except Exception:
            st.session_state["report_current_up_prob"] = None
        
        # í™•ë¥  í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "í˜„ì¬ ìƒìŠ¹ í™•ë¥ ",
                f"{current_prob*100:.2f}%",
                delta=f"{(current_prob-0.5)*100:.2f}%p" if current_prob > 0.5 else f"{(current_prob-0.5)*100:.2f}%p",
                delta_color="normal" if current_prob > 0.5 else "inverse"
            )
        
        with col2:
            current_price = spy['Close'].iloc[-1]
            st.metric("í˜„ì¬ ê°€ê²© (IXIC)", f"${current_price:,.2f}")
        
        with col3:
            # ì‹¤ì œ ìµœì‹  ê±°ë˜ì¼ í‘œì‹œ
            last_date = spy.index[-1]
            last_date_str = str(last_date)[:10] if hasattr(last_date, '__str__') else str(last_date)
            
            # ë‚ ì§œ ë¹„êµ ë° ê²½ê³  í‘œì‹œ
            try:
                last_date_obj = pd.to_datetime(last_date_str).date()
                today = datetime.now().date()
                days_diff = (today - last_date_obj).days
                
                if days_diff > 3:  # 3ì¼ ì´ìƒ ì°¨ì´ë‚˜ë©´ ê²½ê³ 
                    st.metric("ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸", last_date_str, delta=f"{days_diff}ì¼ ì „", delta_color="inverse")
                    st.caption(f"âš ï¸ ìµœì‹  ê±°ë˜ì¼: {actual_last_date_str}")
                else:
                    st.metric("ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸", last_date_str)
            except:
                st.metric("ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸", last_date_str)
        
        # í™•ë¥  í•´ì„
        if current_prob >= 0.7:
            st.success(f"ğŸŸ¢ ë†’ì€ ìƒìŠ¹ í™•ë¥  ({current_prob*100:.1f}%) - ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸")
        elif current_prob >= 0.6:
            st.info(f"ğŸ”µ ì¤‘ê°„ ìƒìŠ¹ í™•ë¥  ({current_prob*100:.1f}%) - ì•½í•œ ë§¤ìˆ˜ ì‹ í˜¸")
        elif current_prob >= 0.4:
            st.warning(f"ğŸŸ¡ ì¤‘ë¦½ ({current_prob*100:.1f}%) - ê´€ë§ ê¶Œì¥")
        else:
            st.error(f"ğŸ”´ ë‚®ì€ ìƒìŠ¹ í™•ë¥  ({current_prob*100:.1f}%) - ë§¤ë„ ê³ ë ¤")
        
        # ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥  í‘œì‹œ
        st.markdown("---")
        st.subheader("ğŸ“… ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥ ")
        
        try:
            # ìµœê·¼ 5ì¼ í™•ë¥  íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
            prob_history_recent = predictor.get_probability_history(X, days=5)
            
            if prob_history_recent is not None and len(prob_history_recent) > 0:
                # get_probability_historyëŠ” k=0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ:
                # - ì²« ë²ˆì§¸ í–‰: ê°€ì¥ ìµœê·¼ ë‚ ì§œ (X.iloc[-1])
                # - ë‹¤ì„¯ ë²ˆì§¸ í–‰: 4ì¼ ì „ ë‚ ì§œ (X.iloc[-5])
                # head(5)ë¡œ ìµœì‹  5ì¼ì„ ê°€ì ¸ì˜¤ë©´ ì´ë¯¸ ìµœì‹  ë‚ ì§œê°€ ì²« ë²ˆì§¸ í–‰ì— ìˆìŒ
                # ì—­ìˆœ ì •ë ¬í•˜ì—¬ ì™¼ìª½ë¶€í„° ì˜¤ë˜ëœ ë‚ ì§œ â†’ ìµœì‹  ë‚ ì§œ ìˆœìœ¼ë¡œ í‘œì‹œ
                recent_5days = prob_history_recent.head(5).copy()
                # ì—­ìˆœ ì •ë ¬ (ì™¼ìª½: ì˜¤ë˜ëœ ë‚ ì§œ, ì˜¤ë¥¸ìª½: ìµœì‹  ë‚ ì§œ)
                recent_5days = recent_5days.iloc[::-1].copy()
                recent_5days['Probability'] = recent_5days['Probability'] * 100
                
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                recent_5days['ë‚ ì§œ'] = recent_5days.index.strftime('%Y-%m-%d')
                recent_5days['ì˜ˆì¸¡ í™•ë¥  (%)'] = recent_5days['Probability']
                
                # ì»¬ëŸ¼ ì„ íƒ ë° ì •ë ¬
                display_df = recent_5days[['ë‚ ì§œ', 'ì˜ˆì¸¡ í™•ë¥  (%)']].copy()

                # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ìµœê·¼ 5ì¼ ìƒìŠ¹ í™•ë¥  ì €ì¥
                try:
                    st.session_state["report_recent5_up"] = [
                        {"date": str(r.get("ë‚ ì§œ")), "prob": float(r.get("ì˜ˆì¸¡ í™•ë¥  (%)")) / 100.0}
                        for r in display_df.to_dict("records")
                        if r.get("ë‚ ì§œ") is not None and r.get("ì˜ˆì¸¡ í™•ë¥  (%)") is not None
                    ]
                except Exception:
                    pass
                
                # 5ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚ ì§œë³„ í™•ë¥  í‘œì‹œ
                cols = st.columns(5)
                for idx, (date_idx, row) in enumerate(display_df.iterrows()):
                    with cols[idx]:
                        prob_value = row['ì˜ˆì¸¡ í™•ë¥  (%)']
                        date_str = row['ë‚ ì§œ']
                        
                        # í™•ë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                        if prob_value >= 70:
                            color = "ğŸŸ¢"
                            delta_color = "normal"
                        elif prob_value >= 60:
                            color = "ğŸ”µ"
                            delta_color = "normal"
                        elif prob_value >= 40:
                            color = "ğŸŸ¡"
                            delta_color = "off"
                        else:
                            color = "ğŸ”´"
                            delta_color = "inverse"
                        
                        # ì´ì „ ë‚ ì§œì™€ì˜ ì°¨ì´ ê³„ì‚° (ì²« ë²ˆì§¸ê°€ ì•„ë‹ˆë©´)
                        delta = None
                        if idx < len(display_df) - 1:
                            prev_prob = display_df.iloc[idx + 1]['ì˜ˆì¸¡ í™•ë¥  (%)']
                            delta = prob_value - prev_prob
                        
                        st.metric(
                            label=date_str,
                            value=f"{prob_value:.2f}%",
                            delta=f"{delta:.2f}%p" if delta is not None else None,
                            delta_color=delta_color if delta is not None else "off"
                        )
                
                # í…Œì´ë¸” í˜•íƒœë¡œë„ í‘œì‹œ (ì„ íƒì‚¬í•­)
                with st.expander("ğŸ“Š ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(
                        display_df.style.format({
                            'ì˜ˆì¸¡ í™•ë¥  (%)': '{:.2f}%'
                        }).background_gradient(
                            subset=['ì˜ˆì¸¡ í™•ë¥  (%)'],
                            cmap='RdYlGn',
                            vmin=0,
                            vmax=100
                        ),
                        use_container_width=True
                    )
                
                # ì‚¬ìš©í•œ ë°ì´í„° ìƒì„¸ ë³´ê¸°
                with st.expander("ğŸ” ì‚¬ìš©í•œ ë°ì´í„° ìƒì„¸ ë³´ê¸°"):
                    st.write("**ìµœê·¼ 5ì¼ê°„ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°ì— ì‚¬ìš©í•œ ë°ì´í„°:**")
                    
                    # ê° ë‚ ì§œë³„ë¡œ ì‚¬ìš©í•œ feature ë°ì´í„° í‘œì‹œ
                    for date_idx in recent_5days.index:
                        date_str = str(date_idx)[:10]
                        st.write(f"### {date_str}")
                        
                        # í•´ë‹¹ ë‚ ì§œì˜ feature ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        if date_idx in X.index:
                            feature_data = X.loc[date_idx]
                            feature_df = pd.DataFrame({
                                'Feature': feature_data.index,
                                'Value': feature_data.values
                            })
                            st.dataframe(feature_df, use_container_width=True, hide_index=True)
                        
                        # í•´ë‹¹ ë‚ ì§œì˜ ì£¼ê°€ ì •ë³´ë„ í‘œì‹œ
                        if date_idx in spy.index:
                            price_info = spy.loc[date_idx]
                            price_cols = st.columns(4)
                            with price_cols[0]:
                                st.metric("ì¢…ê°€", f"${price_info.get('Close', 0):,.2f}")
                            with price_cols[1]:
                                if 'rsi' in price_info:
                                    st.metric("RSI", f"{price_info['rsi']:.2f}")
                            with price_cols[2]:
                                if 'vix' in price_info:
                                    st.metric("VIX", f"{price_info['vix']:.2f}")
                            with price_cols[3]:
                                if 'Change20day' in price_info:
                                    st.metric("Change20day", f"{price_info['Change20day']:.2f}%")
                        st.markdown("---")
            else:
                st.info("ìµœê·¼ 5ì¼ê°„ì˜ í™•ë¥  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ìµœê·¼ 5ì¼ í™•ë¥  í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

        # =========================
        # ì˜ˆì¸¡í™•ë¥ ë³„ í–¥í›„ ìˆ˜ìµë¥  í†µê³„
        # =========================
        with st.expander("ğŸ“Š ì˜ˆì¸¡í™•ë¥ ë³„ í–¥í›„ ìˆ˜ìµë¥  í†µê³„(ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½)", expanded=False):
            st.caption("ê¸°ì¤€: suik_rate(í–¥í›„ 15ê±°ë˜ì¼ ìˆ˜ìµë¥ , %)ë¥¼ í™•ë¥  êµ¬ê°„ë³„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ Nì¼ ì¤‘ ë¯¸ë˜ ìˆ˜ìµë¥ ì´ ì—†ëŠ” êµ¬ê°„(NaN)ì€ ìë™ ì œì™¸ë©ë‹ˆë‹¤.")

            if spy is None or X is None:
                st.info("í†µê³„ë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            elif "suik_rate" not in spy.columns:
                st.info("suik_rate ì»¬ëŸ¼ì´ ì—†ì–´ í†µê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì–´ë–¤ í™•ë¥ ì„ ë³¼ì§€(ìƒìŠ¹/í•˜ë½)
                prob_options = ["ìƒìŠ¹ í™•ë¥ "]
                has_down_model = bool(st.session_state.get("down_model_bytes"))
                if has_down_model:
                    prob_options.append("í•˜ë½ í™•ë¥ (ëª¨ë¸)")

                c0, c1, c2 = st.columns([1.1, 1.0, 0.9])
                with c0:
                    which_prob = st.selectbox("í™•ë¥  ì¢…ë¥˜", prob_options, index=0, key="retstats_prob_kind")
                with c1:
                    lookback_days = st.slider("ë¶„ì„ ê¸°ê°„(ìµœê·¼ N ê±°ë˜ì¼)", 200, max(200, min(5000, len(X))), min(1300, len(X)), step=100, key="retstats_days")
                with c2:
                    bin_size = st.selectbox("í™•ë¥  êµ¬ê°„ í­", [0.05, 0.1, 0.2], index=1, key="retstats_bin")

                def _get_model_for_kind():
                    if which_prob == "ìƒìŠ¹ í™•ë¥ ":
                        return predictor
                    # í•˜ë½ ëª¨ë¸ ë¡œë“œ(ì„¸ì…˜ bytes ê¸°ë°˜)
                    p_down = StockPredictor("stock_model_down.pkl")
                    ok = load_model_from_pkl_bytes(p_down, st.session_state.get("down_model_bytes"))
                    return p_down if ok else None

                model_use = _get_model_for_kind()
                if model_use is None or getattr(model_use, "model", None) is None:
                    st.warning("ì„ íƒí•œ í™•ë¥  ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í•˜ë½ ëª¨ë¸ì€ ë¨¼ì € í•™ìŠµ í•„ìš”)")
                else:
                    # í™•ë¥  íˆìŠ¤í† ë¦¬ (ìµœê·¼ Nì¼)
                    try:
                        prob_hist = model_use.get_probability_history(X, days=int(lookback_days))
                    except Exception as e:
                        st.warning(f"í™•ë¥  íˆìŠ¤í† ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                        prob_hist = None

                    if prob_hist is None or len(prob_hist) == 0:
                        st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        df = prob_hist.copy()
                        df = df.rename(columns={"Probability": "prob"})

                        # âœ… í•˜ì´ë¼ì´íŠ¸ìš© "ê°€ì¥ ìµœê·¼ ë‚ ì§œ" í™•ë¥ ì€ suik_rate í•„í„°ë§ ì „(prob_hist) ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
                        # (suik_rateëŠ” ë¯¸ë˜ ìˆ˜ìµë¥ ì´ë¼ ìµœì‹  ë‚ ì§œëŠ” NaNì¸ ê²½ìš°ê°€ ë§ì•„ dropna í›„ ê¸°ì¤€ì„ ì“°ë©´ êµ¬ê°„ì´ ì–´ê¸‹ë‚¨)
                        try:
                            latest_prob_for_highlight = float(prob_hist.sort_index().iloc[-1]["Probability"])
                        except Exception:
                            latest_prob_for_highlight = None

                        # ìˆ˜ìµë¥  ì •í•©
                        try:
                            df["suik_rate"] = spy.reindex(df.index)["suik_rate"]
                        except Exception:
                            df["suik_rate"] = np.nan
                        df = df.dropna(subset=["prob", "suik_rate"]).copy()
                        if df.empty:
                            st.info("í•´ë‹¹ ê¸°ê°„ì— ìœ íš¨í•œ suik_rate(ë¯¸ë˜ ìˆ˜ìµë¥ ) ë°ì´í„°ê°€ ì—†ì–´ í†µê³„ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê¸°ë³¸ ìš”ì•½
                            hit = (df["suik_rate"] > 0) if which_prob == "ìƒìŠ¹ í™•ë¥ " else (df["suik_rate"] < 0)
                            cA, cB, cC = st.columns(3)
                            with cA:
                                st.metric("í‘œë³¸ ìˆ˜", f"{len(df):,}")
                            with cB:
                                st.metric("í‰ê·  suik_rate(%)", f"{df['suik_rate'].mean():.2f}")
                            with cC:
                                st.metric("ì ì¤‘ë¥ (%)", f"{hit.mean()*100:.1f}")

                            # êµ¬ê°„ë³„ í†µê³„
                            step = float(bin_size)
                            bins = np.arange(0.0, 1.0 + step, step)
                            df["prob_bin"] = pd.cut(df["prob"], bins=bins, include_lowest=True, right=False)

                            def _win_rate(s):
                                if which_prob == "ìƒìŠ¹ í™•ë¥ ":
                                    return float((s > 0).mean())
                                return float((s < 0).mean())

                            grouped = (
                                df.groupby("prob_bin", dropna=True)
                                .agg(
                                    count=("suik_rate", "size"),
                                    prob_mean=("prob", "mean"),
                                    ret_mean=("suik_rate", "mean"),
                                    ret_median=("suik_rate", "median"),
                                    ret_p25=("suik_rate", lambda x: float(np.nanquantile(x, 0.25))),
                                    ret_p75=("suik_rate", lambda x: float(np.nanquantile(x, 0.75))),
                                    win_rate=("suik_rate", _win_rate),
                                )
                                .reset_index()
                            )
                            grouped["win_rate(%)"] = grouped["win_rate"] * 100.0
                            grouped = grouped.drop(columns=["win_rate"])

                            # ë³´ê¸° ì¢‹ê²Œ ì •ë ¬(í™•ë¥  ë‚®ì€â†’ë†’ì€)
                            grouped = grouped.sort_values("prob_bin").reset_index(drop=True)

                            # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì˜ˆì¸¡ì¹˜ê°€ í¬í•¨ëœ êµ¬ê°„ í•˜ì´ë¼ì´íŠ¸(ìµœì‹  í™•ë¥  ê¸°ì¤€)
                            try:
                                if latest_prob_for_highlight is None:
                                    latest_bin_iv = None
                                    latest_bin = None
                                else:
                                    latest_bin_iv = pd.cut(
                                        pd.Series([latest_prob_for_highlight]),
                                        bins=bins,
                                        include_lowest=True,
                                        right=False,
                                    ).iloc[0]
                                    latest_bin = str(latest_bin_iv)
                            except Exception:
                                latest_bin_iv = None
                                latest_bin = None

                            def _hl_latest(row):
                                if latest_bin_iv is None:
                                    return [""] * len(row)
                                try:
                                    is_hit = (row.get("prob_bin") == latest_bin_iv)
                                except Exception:
                                    is_hit = (str(row.get("prob_bin")) == str(latest_bin))
                                return ["background-color: #fff3bf" if is_hit else "" for _ in row]

                            st.dataframe(
                                grouped.style.apply(_hl_latest, axis=1),
                                use_container_width=True,
                            )

                            # í‘œ ì•„ë˜ ì‹œê°í™”(ë§‰ëŒ€: í‰ê·  ìˆ˜ìµë¥ , êº¾ì€ì„ : ì ì¤‘ë¥ )
                            try:
                                x_labels = grouped["prob_bin"].astype(str)
                                # ìµœì‹  í™•ë¥  êµ¬ê°„ í•˜ì´ë¼ì´íŠ¸ ìƒ‰(ë§‰ëŒ€/ì„  ë§ˆì»¤)
                                try:
                                    highlight_mask = grouped["prob_bin"].apply(lambda v: v == latest_bin_iv)
                                except Exception:
                                    highlight_mask = grouped["prob_bin"].astype(str) == str(latest_bin)

                                bar_colors = [
                                    "#FFC107" if bool(m) else SHINHAN_SKY
                                    for m in highlight_mask.tolist()
                                ]
                                fig = make_subplots(specs=[[{"secondary_y": True}]])
                                fig.add_trace(
                                    go.Bar(
                                        x=x_labels,
                                        y=grouped["ret_mean"],
                                        name="í‰ê·  suik_rate(%)",
                                        marker_color=bar_colors,
                                    ),
                                    secondary_y=False,
                                )
                                fig.add_trace(
                                    go.Scatter(
                                        x=x_labels,
                                        y=grouped["win_rate(%)"],
                                        name="ì ì¤‘ë¥ (%)",
                                        mode="lines+markers",
                                        line=dict(color=SHINHAN_BLUE, width=2),
                                        marker=dict(
                                            size=7,
                                            color=["#FFC107" if bool(m) else SHINHAN_BLUE for m in highlight_mask.tolist()],
                                        ),
                                    ),
                                    secondary_y=True,
                                )
                                fig.update_xaxes(title_text="ì˜ˆì¸¡ í™•ë¥  êµ¬ê°„")
                                fig.update_yaxes(title_text="í‰ê·  suik_rate(%)", secondary_y=False)
                                fig.update_yaxes(title_text="ì ì¤‘ë¥ (%)", secondary_y=True, range=[0, 100])
                                fig.update_layout(
                                    height=420,
                                    hovermode="x unified",
                                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
                                )
                                st.plotly_chart(fig, use_container_width=True)
                                # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš©: í‘œ/ê·¸ë˜í”„ ì €ì¥
                                try:
                                    st.session_state["report_return_stats"] = {
                                        "kind": which_prob,
                                        "lookback_days": int(lookback_days),
                                        "bin_size": float(step),
                                        "latest_bin": latest_bin,
                                        "rows": grouped.to_dict("records"),
                                    }
                                    st.session_state["report_return_stats_fig_json"] = fig.to_json()
                                except Exception:
                                    pass
                            except Exception as e:
                                st.caption(f"ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # í™•ë¥  ì¶”ì´ ê·¸ë˜í”„
        st.subheader("ğŸ“ˆ í™•ë¥  ì¶”ì´ ê·¸ë˜í”„")
        
        prob_history = predictor.get_probability_history(X, days=500)
        
        if prob_history is not None and len(prob_history) > 0:
            # í™•ë¥  ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ë¡œ ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            start_date_prob = prob_history.index[0]
            end_date_prob = prob_history.index[-1]
            
            # ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í™•ë¥  ë°ì´í„°ì™€ ê°™ì€ ë‚ ì§œ ë²”ìœ„)
            # (ë„¤íŠ¸ì›Œí¬/í”„ë¡ì‹œ í™˜ê²½ ì´ìŠˆê°€ ìˆì–´ë„ ì•„ë˜ ì„¹ì…˜(í•˜ë½ í™•ë¥ )ê¹Œì§€ëŠ” ë Œë”ë§ë˜ë„ë¡ ë°©ì–´)
            try:
                price_data = fdr.DataReader('IXIC', start_date_prob, end_date_prob)
            except Exception:
                price_data = None
            
            # í™•ë¥  ë°ì´í„°ì˜ ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
            prob_dates = prob_history.index
            
            # ì£¼ê°€ ë°ì´í„°ë¥¼ í™•ë¥  ë°ì´í„°ì˜ ë‚ ì§œì™€ ë§ì¶”ê¸°
            try:
                price_aligned = price_data.reindex(prob_dates, method='nearest') if price_data is not None else None
            except Exception:
                price_aligned = None
            
            # ê·¸ë˜í”„ ìƒì„±
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            # í™•ë¥  ê·¸ë˜í”„ (í™•ë¥ ì´ ìˆëŠ” ë‚ ì§œë§Œ í‘œì‹œ)
            fig.add_trace(
                go.Scatter(
                    x=prob_dates,
                    y=prob_history['Probability'] * 100,
                    name="ìƒìŠ¹ í™•ë¥  (%)",
                    line=dict(color='skyblue', width=2),
                    mode='lines+markers',
                    marker=dict(size=4)
                ),
                secondary_y=False
            )
            
            # ê¸°ì¤€ì„  (50%)
            fig.add_hline(
                y=50,
                line_dash="dash",
                line_color="gray",
                opacity=0.5,
                annotation_text="ê¸°ì¤€ì„  (50%)",
                secondary_y=False
            )
            
            # ì£¼ê°€ ê·¸ë˜í”„ (í™•ë¥  ë°ì´í„°ì™€ ê°™ì€ ë‚ ì§œ ì‚¬ìš©)
            if price_aligned is not None and len(price_aligned) > 0:
                col_price = 'Adj Close' if 'Adj Close' in price_aligned.columns else ('Close' if 'Close' in price_aligned.columns else None)
            else:
                col_price = None

            if col_price is not None and not price_aligned[col_price].isna().all():
                fig.add_trace(
                    go.Scatter(
                        x=prob_dates,
                        y=price_aligned[col_price],
                        name="IXIC ê°€ê²©",
                        line=dict(color='red', width=1, dash='dot'),
                        opacity=0.5
                    ),
                    secondary_y=True
                )
            
            fig.update_xaxes(title_text="ë‚ ì§œ")
            fig.update_yaxes(title_text="ìƒìŠ¹ í™•ë¥  (%)", secondary_y=False)
            fig.update_yaxes(title_text="ì£¼ê°€ (USD)", secondary_y=True)
            fig.update_layout(
                title="ì£¼ê°€ ìƒìŠ¹ í™•ë¥  ì¶”ì´ ë° IXIC ê°€ê²©",
                height=600,
                hovermode='x unified',
                xaxis=dict(
                    tickmode='linear',
                    tick0=prob_dates[0],
                    dtick=86400000.0 * 30  # ì•½ 30ì¼ ê°„ê²©
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© figure ì €ì¥ (json)
            try:
                st.session_state["report_fig_prob_trend_json"] = fig.to_json()
            except Exception:
                pass
        else:
            st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆì–´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¨¼ì € ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°ì´ ì™„ë£Œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")

        # =========================
        # ìµœê·¼ 5ë…„: ë‚˜ìŠ¤ë‹¥/ S&P/ ë‹¤ìš° vs ì˜ˆì¸¡í™•ë¥  ë¹„êµ
        # =========================
        st.subheader("ğŸ“Š ìµœê·¼ 5ë…„: ë‚˜ìŠ¤ë‹¥ / S&P500 / ë‹¤ìš°ì¡´ìŠ¤ vs ì˜ˆì¸¡ í™•ë¥ ")

        try:
            # í™•ë¥  íˆìŠ¤í† ë¦¬(ìµœëŒ€í•œ ê¸¸ê²Œ) â†’ ìµœê·¼ 5ë…„ í•„í„°
            prob_all = predictor.get_probability_history(X, days=len(X))
            if prob_all is None or len(prob_all) == 0:
                st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                prob_all = prob_all.sort_index()
                end_dt = prob_all.index.max()
                start_dt = end_dt - pd.DateOffset(years=5)
                prob_5y = prob_all.loc[prob_all.index >= start_dt].copy()
                prob_5y['prob_pct'] = prob_5y['Probability'] * 100.0

                # ì§€ìˆ˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì‹¬ë³¼ í›„ë³´ë¥¼ ì—¬ëŸ¬ ê°œ ë‘¬ì„œ í˜¸í™˜ì„± í™•ë³´)
                start_fetch = start_dt.date()
                end_fetch = (end_dt.date() + timedelta(days=1))

                nas_sym, nas = fetch_index_adj_close(['IXIC', '^IXIC'], start_fetch, end_fetch)
                sp_sym, sp = fetch_index_adj_close(['US500', 'SPX', '^GSPC'], start_fetch, end_fetch)
                dow_sym, dow = fetch_index_adj_close(['DJI', '^DJI'], start_fetch, end_fetch)

                # í™•ë¥  ë‚ ì§œ ì¸ë±ìŠ¤ì— ë§ì¶° ì •ë ¬(ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ forward fill)
                idx = prob_5y.index
                nas_a = nas.reindex(idx, method='ffill')
                sp_a = sp.reindex(idx, method='ffill')
                dow_a = dow.reindex(idx, method='ffill')

                # ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì—†ì• ê¸° ìœ„í•´ 100 ê¸°ì¤€ ë¦¬ë² ì´ìŠ¤
                nas_r = rebase_to_100(nas_a)
                sp_r = rebase_to_100(sp_a)
                dow_r = rebase_to_100(dow_a)

                fig2 = make_subplots(specs=[[{"secondary_y": True}]])

                # ì˜ˆì¸¡ í™•ë¥ (ì¢Œì¸¡ ì¶•)
                fig2.add_trace(
                    go.Scatter(
                        x=idx,
                        y=prob_5y['prob_pct'],
                        name="ì˜ˆì¸¡ ìƒìŠ¹ í™•ë¥ (%)",
                        line=dict(color='skyblue', width=2),
                        mode='lines'
                    ),
                    secondary_y=False
                )

                # ì§€ìˆ˜(ìš°ì¸¡ ì¶•, ë¦¬ë² ì´ìŠ¤ 100)
                fig2.add_trace(
                    go.Scatter(
                        x=idx,
                        y=nas_r,
                        name=f"ë‚˜ìŠ¤ë‹¥({nas_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                        line=dict(color='#FF4B4B', width=1.5),
                        mode='lines'
                    ),
                    secondary_y=True
                )
                fig2.add_trace(
                    go.Scatter(
                        x=idx,
                        y=sp_r,
                        name=f"S&P500({sp_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                        line=dict(color='#2ECC71', width=1.5),
                        mode='lines'
                    ),
                    secondary_y=True
                )
                fig2.add_trace(
                    go.Scatter(
                        x=idx,
                        y=dow_r,
                        name=f"ë‹¤ìš°({dow_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                        line=dict(color='#F1C40F', width=1.5),
                        mode='lines'
                    ),
                    secondary_y=True
                )

                fig2.update_xaxes(title_text="ë‚ ì§œ")
                fig2.update_yaxes(title_text="ì˜ˆì¸¡ ìƒìŠ¹ í™•ë¥  (%)", secondary_y=False, range=[0, 100])
                fig2.update_yaxes(title_text="ì§€ìˆ˜ ë¦¬ë² ì´ìŠ¤ (ì²«ê°’=100)", secondary_y=True)
                fig2.update_layout(
                    height=650,
                    hovermode='x unified',
                    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
                    title="ìµœê·¼ 5ë…„ ì§€ìˆ˜ ì›€ì§ì„(ë¦¬ë² ì´ìŠ¤)ê³¼ ì˜ˆì¸¡ í™•ë¥  ë¹„êµ"
                )

                st.plotly_chart(fig2, use_container_width=True)

                # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© figure ì €ì¥ (json)
                try:
                    st.session_state["report_fig_index_compare_json"] = fig2.to_json()
                except Exception:
                    pass

                with st.expander("â„¹ï¸ ê³„ì‚° ë°©ì‹ / ì£¼ì˜ì‚¬í•­"):
                    st.write(
                        "- ì§€ìˆ˜ëŠ” ë‚ ì§œë³„ ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì—†ì• ê¸° ìœ„í•´ **ì²« ê°’=100ìœ¼ë¡œ ë¦¬ë² ì´ìŠ¤**í•´ì„œ í‘œì‹œí•©ë‹ˆë‹¤.\n"
                        "- ì˜ˆì¸¡ í™•ë¥ ì€ ëª¨ë¸ì´ í•™ìŠµëœ feature(X) ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œëœ ê°’ì…ë‹ˆë‹¤.\n"
                        "- FinanceDataReader ì‹¬ë³¼ì€ í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ í›„ë³´ë¥¼ ì—¬ëŸ¬ ê°œ ì‹œë„í•©ë‹ˆë‹¤."
                    )
        except Exception as e:
            st.warning(f"ìµœê·¼ 5ë…„ ë¹„êµ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ì£¼ìš” ì§€í‘œ í‘œì‹œ
        st.subheader("ğŸ“Š ì£¼ìš” ê¸°ìˆ ì  ì§€í‘œ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if 'rsi' in spy.columns:
                current_rsi = spy['rsi'].iloc[-1]
                st.metric("RSI", f"{current_rsi:.2f}")
        
        with col2:
            if 'macd' in spy.columns:
                current_macd = spy['macd'].iloc[-1]
                st.metric("MACD", f"{current_macd:.2f}")
        
        with col3:
            if 'vix' in spy.columns:
                current_vix = spy['vix'].iloc[-1]
                st.metric("VIX", f"{current_vix:.2f}")
        
        with col4:
            if 'ratio_sma50' in spy.columns:
                current_ratio = spy['ratio_sma50'].iloc[-1]
                st.metric("SMA50 ë¹„ìœ¨", f"{current_ratio*100:.2f}%")
        
        # ìµœê·¼ í™•ë¥  ë°ì´í„° í…Œì´ë¸”
        with st.expander("ğŸ“‹ ìµœê·¼ í™•ë¥  ë°ì´í„° ë³´ê¸°"):
            if prob_history is not None:
                recent_data = prob_history.tail(30).copy()
                recent_data['Probability'] = recent_data['Probability'] * 100
                recent_data = recent_data.rename(columns={'Probability': 'ìƒìŠ¹ í™•ë¥  (%)'})
                st.dataframe(recent_data.style.format({'ìƒìŠ¹ í™•ë¥  (%)': '{:.2f}'}), use_container_width=True)
        
        # ëª¨ë¸ ì •ë³´
        st.subheader("ğŸ¤– ëª¨ë¸ ì •ë³´")
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"**ëª¨ë¸ íƒ€ì…**: RandomForest Classifier\n\n"
                   f"**íŠ¹ì„± ìˆ˜**: {len(predictor.feature_columns)}\n\n"
                   f"**íŠ¸ë¦¬ ìˆ˜**: {predictor.model.n_estimators}")
        
        with col2:
            if hasattr(predictor.model, 'oob_score_'):
                st.info(f"**OOB ì •í™•ë„**: {predictor.model.oob_score_:.3f}\n\n"
                       f"**ìµœëŒ€ ê¹Šì´**: {predictor.model.max_depth}\n\n"
                       f"**ìµœì†Œ ìƒ˜í”Œ ë¦¬í”„**: {predictor.model.min_samples_leaf}")

        # =========================
        # í•˜ë½ í™•ë¥ : íƒ­ ì—†ì´ í•˜ë‹¨ì— í‘œê¸°
        # =========================
        st.markdown("---")
        st.subheader("ğŸ“‰ í•˜ë½ í™•ë¥ (ëª¨ë¸ ìƒˆë¡œ ìƒì„±)")
        st.caption("í•˜ë½ ëª¨ë¸ì€ ì—¬ê¸°ì„œ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤. (SMAëŠ” ì„¸ì…˜/ì—…ë¡œë“œ ë°ì´í„°ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ê³„ì‚°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)")

        sma_dataframes = st.session_state.get("sma_dataframes")
        if not (isinstance(sma_dataframes, dict) and sma_dataframes):
            st.warning("SMA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. SMA zip/íŒ¨í‚¤ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜, ë¨¼ì € SMA ìˆ˜ì§‘ì„ ì§„í–‰í•˜ì„¸ìš”.")
        else:
            today_str = datetime.now().date().isoformat()
            sma_sig = (
                st.session_state.get("_sma_upload_sig")
                or ("sma_cache", st.session_state.get("sma_collector_date"), len(sma_dataframes))
            )
            cached_ok = (
                st.session_state.get("down_model_date") == today_str
                and st.session_state.get("down_model_sma_sig") == sma_sig
                and st.session_state.get("down_model_bytes") is not None
            )

            train_down_clicked = st.button("ğŸ“‰ í•˜ë½ ëª¨ë¸ í•™ìŠµ í›„ ì˜ˆì¸¡", type="primary", key="train_down_button")

            if train_down_clicked:
                with st.status("ğŸ”„ í•˜ë½ ëª¨ë¸ í•™ìŠµ ì¤‘...", expanded=True) as status:
                    try:
                        st.write("1/3: í•™ìŠµ ë°ì´í„° ì¤€ë¹„(IXIC + í”¼ì²˜)")

                        collector_down = StockDataCollector(
                            start_date="2015-01-01",
                            end_date=datetime.now().date() + timedelta(days=1),
                        )
                        collector_down.dataframes = sma_dataframes.copy()  # SMA ì¬ì‚¬ìš©

                        spy_down = collector_down.prepare_target_data("IXIC", for_prediction=False)
                        spy_down = collector_down.add_features(spy_down, skip_sma=False, for_prediction=False)

                        X_down = build_feature_matrix(spy_down)
                        y_down = spy_down.get("TargetDown")
                        if y_down is None:
                            raise RuntimeError("TargetDown ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (stock_analysis_refactored.py ë³€ê²½ì´ ë°˜ì˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")

                        mask = ~pd.isna(y_down)
                        X_down = X_down.loc[mask]
                        y_down = y_down.loc[mask]

                        # ìƒìŠ¹ ëª¨ë¸ê³¼ ë™ì¼í•œ í”¼ì²˜ì…‹ìœ¼ë¡œ í•™ìŠµ(ê°€ëŠ¥í•œ ê²½ìš°)
                        if getattr(predictor, "feature_columns", None):
                            X_down = X_down.reindex(columns=predictor.feature_columns).fillna(0)

                        st.write(f"2/3: ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ìƒ˜í”Œ {len(X_down)}, íŠ¹ì„± {len(X_down.columns)})")

                        predictor_down = StockPredictor("stock_model_down.pkl")
                        predictor_down.train_model(
                            X_down,
                            y_down,
                            # ìƒìŠ¹ ëª¨ë¸ê³¼ ë™ì¼ ì¡°ê±´(íŠ¸ë¦¬ ìˆ˜ í¬í•¨) ì ìš©
                            n_estimators=2000,
                            progress_callback=None,
                            status_callback=None,
                        )

                        st.write("3/3: ëª¨ë¸ ì €ì¥(ì„¸ì…˜)")
                        st.session_state["down_model_bytes"] = export_model_pkl_bytes(predictor_down)
                        st.session_state["down_model_date"] = today_str
                        st.session_state["down_model_sma_sig"] = sma_sig
                        status.update(label="âœ… í•˜ë½ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ", state="complete")
                    except Exception as e:
                        status.update(label="âŒ í•˜ë½ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨", state="error")
                        st.error(str(e))

            if cached_ok or (st.session_state.get("down_model_bytes") is not None):
                predictor_down_use = StockPredictor("stock_model_down.pkl")
                ok = load_model_from_pkl_bytes(predictor_down_use, st.session_state["down_model_bytes"])
                if not ok:
                    st.error("í•˜ë½ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    # feature mismatch ë°©ì§€: Seriesë¡œ ì „ë‹¬(ì»¬ëŸ¼ align ê°€ëŠ¥)
                    down_prob = predictor_down_use.get_current_probability(X.iloc[-1])
                    if down_prob is None:
                        st.error("í•˜ë½ í™•ë¥  ê³„ì‚° ì‹¤íŒ¨")
                    else:
                        # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ì„¸ì…˜ ìƒíƒœ ì €ì¥
                        try:
                            st.session_state["report_current_down_prob"] = float(down_prob)
                        except Exception:
                            st.session_state["report_current_down_prob"] = None

                        st.metric("í˜„ì¬ í•˜ë½ í™•ë¥ ", f"{down_prob*100:.2f}%")
                        st.caption(f"ê¸°ì¤€ì¼: {str(spy.index[-1])[:10]}")

                        with st.expander("ğŸ“‰ í•˜ë½ í™•ë¥  ìƒì„¸ ë³´ê¸°", expanded=False):
                            st.subheader("ğŸ“… ìµœê·¼ 5ì¼ê°„ í•˜ë½ í™•ë¥ ")
                            down_hist_5 = predictor_down_use.get_probability_history(X, days=5)
                            if down_hist_5 is not None and len(down_hist_5) > 0:
                                tmp = down_hist_5.copy().sort_index()
                                # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© ìµœê·¼ 5ì¼ í•˜ë½ í™•ë¥  ì €ì¥
                                try:
                                    st.session_state["report_recent5_down"] = [
                                        {"date": str(idx)[:10], "prob": float(p)}
                                        for idx, p in tmp["Probability"].items()
                                        if p is not None and not pd.isna(p)
                                    ]
                                except Exception:
                                    pass
                                tmp["Probability"] = tmp["Probability"] * 100
                                st.dataframe(tmp.rename(columns={"Probability": "í•˜ë½ í™•ë¥  (%)"}), use_container_width=True)
                            else:
                                st.info("ìµœê·¼ 5ì¼ í™•ë¥  ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            # =========================
                            # ê·¸ë˜í”„ 2ì¢…
                            # 1) í™•ë¥  ì¶”ì´(í™•ë¥  + IXIC)
                            # 2) ìµœê·¼ 5ë…„ ì§€ìˆ˜ ë¹„êµ(ë‚˜ìŠ¤ë‹¥/ë‹¤ìš°/S&P) + í™•ë¥ 
                            # =========================

                            st.markdown("---")
                            st.subheader("ğŸ“ˆ í™•ë¥  ì¶”ì´ ê·¸ë˜í”„ (í•˜ë½ í™•ë¥ )")

                            prob_history_down = predictor_down_use.get_probability_history(X, days=min(500, len(X)))
                            if prob_history_down is not None and len(prob_history_down) > 0:
                                prob_history_down = prob_history_down.sort_index()
                                start_date_prob = prob_history_down.index[0]
                                end_date_prob = prob_history_down.index[-1]

                                try:
                                    price_data = fdr.DataReader('IXIC', start_date_prob, end_date_prob)
                                    price_aligned = price_data.reindex(prob_history_down.index, method='nearest')
                                except Exception:
                                    price_aligned = None

                                fig_down = make_subplots(specs=[[{"secondary_y": True}]])
                                fig_down.add_trace(
                                    go.Scatter(
                                        x=prob_history_down.index,
                                        y=prob_history_down['Probability'] * 100,
                                        name="í•˜ë½ í™•ë¥  (%)",
                                        line=dict(color='#FF4B4B', width=2),
                                        mode='lines+markers',
                                        marker=dict(size=4),
                                    ),
                                    secondary_y=False
                                )
                                fig_down.add_hline(
                                    y=50,
                                    line_dash="dash",
                                    line_color="gray",
                                    opacity=0.5,
                                    annotation_text="ê¸°ì¤€ì„  (50%)",
                                    secondary_y=False
                                )
                                if price_aligned is not None and len(price_aligned) > 0:
                                    col_price = 'Adj Close' if 'Adj Close' in price_aligned.columns else ('Close' if 'Close' in price_aligned.columns else None)
                                    if col_price is not None and not price_aligned[col_price].isna().all():
                                        fig_down.add_trace(
                                            go.Scatter(
                                                x=prob_history_down.index,
                                                y=price_aligned[col_price],
                                                name="IXIC ê°€ê²©",
                                                line=dict(color='red', width=1, dash='dot'),
                                                opacity=0.5
                                            ),
                                            secondary_y=True
                                        )

                                fig_down.update_xaxes(title_text="ë‚ ì§œ")
                                fig_down.update_yaxes(title_text="í•˜ë½ í™•ë¥  (%)", secondary_y=False, range=[0, 100])
                                fig_down.update_yaxes(title_text="ì£¼ê°€ (USD)", secondary_y=True)
                                fig_down.update_layout(
                                    title="í•˜ë½ í™•ë¥  ì¶”ì´ ë° IXIC ê°€ê²©",
                                    height=600,
                                    hovermode='x unified',
                                )
                                st.plotly_chart(fig_down, use_container_width=True)
                                # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© figure ì €ì¥ (json)
                                try:
                                    st.session_state["report_fig_down_trend_json"] = fig_down.to_json()
                                except Exception:
                                    pass
                            else:
                                st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆì–´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            st.subheader("ğŸ“Š ìµœê·¼ 5ë…„: ë‚˜ìŠ¤ë‹¥ / S&P500 / ë‹¤ìš°ì¡´ìŠ¤ vs í•˜ë½ í™•ë¥ ")
                            try:
                                prob_all = predictor_down_use.get_probability_history(X, days=len(X))
                                if prob_all is None or len(prob_all) == 0:
                                    st.info("í™•ë¥  íˆìŠ¤í† ë¦¬ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    prob_all = prob_all.sort_index()
                                    end_dt = prob_all.index.max()
                                    start_dt = end_dt - pd.DateOffset(years=5)
                                    prob_5y = prob_all.loc[prob_all.index >= start_dt].copy()
                                    prob_5y['prob_pct'] = prob_5y['Probability'] * 100.0

                                    start_fetch = start_dt.date()
                                    end_fetch = (end_dt.date() + timedelta(days=1))

                                    nas_sym, nas = fetch_index_adj_close(['IXIC', '^IXIC'], start_fetch, end_fetch)
                                    sp_sym, sp = fetch_index_adj_close(['US500', 'SPX', '^GSPC'], start_fetch, end_fetch)
                                    dow_sym, dow = fetch_index_adj_close(['DJI', '^DJI'], start_fetch, end_fetch)

                                    idx = prob_5y.index
                                    nas_a = nas.reindex(idx, method='ffill')
                                    sp_a = sp.reindex(idx, method='ffill')
                                    dow_a = dow.reindex(idx, method='ffill')

                                    nas_r = rebase_to_100(nas_a)
                                    sp_r = rebase_to_100(sp_a)
                                    dow_r = rebase_to_100(dow_a)

                                    fig2 = make_subplots(specs=[[{"secondary_y": True}]])
                                    fig2.add_trace(
                                        go.Scatter(
                                            x=idx,
                                            y=prob_5y['prob_pct'],
                                            name="í•˜ë½ í™•ë¥ (%)",
                                            line=dict(color='#FF4B4B', width=2),
                                            mode='lines'
                                        ),
                                        secondary_y=False
                                    )
                                    fig2.add_trace(
                                        go.Scatter(
                                            x=idx,
                                            y=nas_r,
                                            name=f"ë‚˜ìŠ¤ë‹¥({nas_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                            line=dict(color='#0046ff', width=1.5),
                                            mode='lines'
                                        ),
                                        secondary_y=True
                                    )
                                    fig2.add_trace(
                                        go.Scatter(
                                            x=idx,
                                            y=sp_r,
                                            name=f"S&P500({sp_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                            line=dict(color='#2ECC71', width=1.5),
                                            mode='lines'
                                        ),
                                        secondary_y=True
                                    )
                                    fig2.add_trace(
                                        go.Scatter(
                                            x=idx,
                                            y=dow_r,
                                            name=f"ë‹¤ìš°({dow_sym}) ë¦¬ë² ì´ìŠ¤(100)",
                                            line=dict(color='#F1C40F', width=1.5),
                                            mode='lines'
                                        ),
                                        secondary_y=True
                                    )

                                    fig2.update_xaxes(title_text="ë‚ ì§œ")
                                    fig2.update_yaxes(title_text="í•˜ë½ í™•ë¥  (%)", secondary_y=False, range=[0, 100])
                                    fig2.update_yaxes(title_text="ì§€ìˆ˜ ë¦¬ë² ì´ìŠ¤ (ì²«ê°’=100)", secondary_y=True)
                                    fig2.update_layout(
                                        height=650,
                                        hovermode='x unified',
                                        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
                                        title="ìµœê·¼ 5ë…„ ì§€ìˆ˜ ì›€ì§ì„(ë¦¬ë² ì´ìŠ¤)ê³¼ í•˜ë½ í™•ë¥  ë¹„êµ"
                                    )
                                    st.plotly_chart(fig2, use_container_width=True)
                                    # HTML ì €ì¥(ë¦¬í¬íŠ¸)ìš© figure ì €ì¥ (json)
                                    try:
                                        st.session_state["report_fig_down_index_compare_json"] = fig2.to_json()
                                    except Exception:
                                        pass
                            except Exception as e:
                                st.warning(f"ìµœê·¼ 5ë…„ ë¹„êµ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

        # =========================
        # í™”ë©´ ë¶„ì„ ê²°ê³¼ HTML ì €ì¥
        # =========================
        st.markdown("---")
        st.subheader("ğŸ’¾ í™”ë©´ ë¶„ì„ ê²°ê³¼ ì €ì¥")
        report_html = build_screen_analysis_report_html_from_session_state()
        if report_html is None:
            st.info("ì €ì¥í•  ê²°ê³¼(í™•ë¥ /ê·¸ë˜í”„)ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            st.download_button(
                label="â¬‡ï¸ í™”ë©´ ë¶„ì„ ê²°ê³¼ HTML ì €ì¥(.html)",
                data=report_html.encode("utf-8"),
                file_name=f"screen_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html",
                help="ê°€ëŠ¥í•˜ë©´ ê·¸ë˜í”„ë¥¼ PNG ì´ë¯¸ì§€ë¡œ í¬í•¨í•´ ì €ì¥í•©ë‹ˆë‹¤. (í™˜ê²½ì— ë”°ë¼ interactive Plotlyë¡œ ì €ì¥ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)",
            )
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ í”Œë˜ê·¸ ë¦¬ì…‹ (ë§¤ ì‹¤í–‰ë§ˆë‹¤ ë‚´ë¦¬ë©´ rerun ë£¨í”„ ë°œìƒ ê°€ëŠ¥)
        if model_option == "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©" and st.session_state.get('run_prediction', False):
            st.session_state.run_prediction = False

else:
    st.warning("âš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ ë¡œë“œí•˜ì„¸ìš”.")
    
    # ì‚¬ìš© ë°©ë²• ì•ˆë‚´
    st.info("""
    ### ì‚¬ìš© ë°©ë²•:
    1. **ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©**: ì €ì¥ëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
    2. **ìƒˆ ëª¨ë¸ í•™ìŠµ**: 
       - 'ìƒˆ ëª¨ë¸ í•™ìŠµ' ì˜µì…˜ ì„ íƒ
       - 'ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘' ì²´í¬ (ì„ íƒì‚¬í•­)
       - 'ëª¨ë¸ í•™ìŠµ ì‹œì‘' ë²„íŠ¼ í´ë¦­
       - í•™ìŠµì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ëª¨ë¸ì´ ì €ì¥ë©ë‹ˆë‹¤.
    
    **ì°¸ê³ **: ëª¨ë¸ í•™ìŠµì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ìˆ˜ì‹­ ë¶„ ì†Œìš” ê°€ëŠ¥).
    """)

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        <p>ğŸ“ˆ ì£¼ê°€ ì˜ˆì¸¡ í™•ë¥  ë¶„ì„ ëŒ€ì‹œë³´ë“œ</p>
        <p>âš ï¸ ì´ ì˜ˆì¸¡ì€ ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ íˆ¬ì ê²°ì •ì— ì‚¬ìš©í•˜ê¸° ì „ì— ì „ë¬¸ê°€ì˜ ì¡°ì–¸ì„ êµ¬í•˜ì„¸ìš”.</p>
    </div>
    """,
    unsafe_allow_html=True
)
